<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">

<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">


  <script>
  (function(i,s,o,g,r,a,m){i["DaoVoiceObject"]=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;a.charset="utf-8";m.parentNode.insertBefore(a,m)})(window,document,"script",('https:' == document.location.protocol ? 'https:' : 'http:') + "//widget.daovoice.io/widget/0f81ff2f.js","daovoice")
  daovoice('init', {
      app_id: "e77a7f88"
    });
  daovoice('update');
  </script>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Lobster Two:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Artificial Intelligence,Deep Leanring,Machine Learning," />








  <link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico?v=5.1.2" />






<meta name="description" content="Lecture 10主要讲解了循环神经网络模型的结构、前向传播与反向传播，并由此引出了LSTM（长短期记忆网络），除此之外还介绍了图像标注、视觉问答等前沿问题。">
<meta name="keywords" content="Artificial Intelligence,Deep Leanring,Machine Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="CS231n Lecture 10 Recurrent Neural Networks">
<meta property="og:url" content="http://yoursite.com/2018/10/01/CS231n Lecture 10 Recurrent Neural Networks/index.html">
<meta property="og:site_name" content="KunBB&#39;s blog">
<meta property="og:description" content="Lecture 10主要讲解了循环神经网络模型的结构、前向传播与反向传播，并由此引出了LSTM（长短期记忆网络），除此之外还介绍了图像标注、视觉问答等前沿问题。">
<meta property="og:locale" content="en">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/1.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/2.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/3.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/4.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/5.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/6.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/7.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/8.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/9.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/10.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/11.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/12.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/13.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/14.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/15.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/16.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/17.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/18.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/19.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/20.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/21.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/22.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/23.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/24.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/25.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/26.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/36.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/27.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/28.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/29.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/30.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/31.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/32.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/33.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/34.png">
<meta property="og:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/35.png">
<meta property="og:updated_time" content="2018-10-01T15:42:32.191Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CS231n Lecture 10 Recurrent Neural Networks">
<meta name="twitter:description" content="Lecture 10主要讲解了循环神经网络模型的结构、前向传播与反向传播，并由此引出了LSTM（长短期记忆网络），除此之外还介绍了图像标注、视觉问答等前沿问题。">
<meta name="twitter:image" content="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/1.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.2',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/10/01/CS231n Lecture 10 Recurrent Neural Networks/"/>





  <title>CS231n Lecture 10 Recurrent Neural Networks | KunBB's blog</title>
  





  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?d76fd55ad2c6a913abb69c04b4c9aadf";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->




</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">KunBB's blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">The only time you should ever look back is to see how far you've come.</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
			
		  
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/10/01/CS231n Lecture 10 Recurrent Neural Networks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Yunkun Xu">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1505221430290&amp;di=5d6a88d013890d4f520618b024b4aaed&amp;imgtype=0&amp;src=http%3A%2F%2Fimg3.duitang.com%2Fuploads%2Fitem%2F201601%2F03%2F20160103085338_eyBCL.jpeg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="KunBB's blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">CS231n Lecture 10 Recurrent Neural Networks</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-10-01T09:25:00+08:00">
                2018-10-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/CS231n/" itemprop="url" rel="index">
                    <span itemprop="name">CS231n</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          
             <span id="/2018/10/01/CS231n Lecture 10 Recurrent Neural Networks/" class="leancloud_visitors" data-flag-title="CS231n Lecture 10 Recurrent Neural Networks">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Heat&#58;</span>
               
                 <span class="leancloud-visitors-count"></span>
				 <span>℃</span>
             </span>
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  4,258
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Reading time &asymp;</span>
                
                <span title="Reading time">
                  15
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>Lecture 10主要讲解了循环神经网络模型的结构、前向传播与反向传播，并由此引出了LSTM（长短期记忆网络），除此之外还介绍了图像标注、视觉问答等前沿问题。<br><a id="more"></a></p>
<h1 id="RNN网络结构"><a href="#RNN网络结构" class="headerlink" title="RNN网络结构"></a>RNN网络结构</h1><p><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/1.png" alt="Loading..."><br>RNN通常用来预测一个时间序列向量。每个RNN网络都有如上图所示这样一个小小的循环核心单元。X为输入，将其传入RNN，RNN有一个内部隐藏态（internal hidden state），这一隐藏态会在RNN每次读取新的输入时更新。当模型下一次读取输入时，隐藏状态同时将结果反馈至模型。</p>
<p>循环神经网络隐藏状态$h_t$更新公式：<br><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/2.png" alt="Loading..."><br>我们对某种循环关系用函数$f$进行计算。函数$f$依赖于权重$W$，接收输入隐藏态$h_{t-1}$和输入$x_t$，然后输出下一个隐藏态$h_t$。如果我们想要在网络的每一步都产生一些输出，那么我们可以增加全连接层，根据每一步的隐藏态做出决策。<br>（注意，每一时间步的函数$f$和参数$W$都是相同的。）</p>
<p>Vanilla RNN 络结构图与更新公式：<br><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/3.png" alt="Loading..."><br>Vanilla RNN 计算图：<br><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/4.png" alt="Loading..."><br>$h_0$为初始状态，一般$h_0=0$。由上图可以看出每一时间步都在使用相同的$f$和$W$。由反向传播原理可知，$W$最后的梯度是所有时间步下独立计算出的梯度之和。</p>
<h2 id="Many-to-many"><a href="#Many-to-many" class="headerlink" title="Many to many"></a>Many to many</h2><p><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/5.png" alt="Loading..."><br>$Y_t$可以是每个时间步的类别得分，$L_t$是对应时间步下的损失（如softmax等），计算$L_t$需要序列在每个时间步下都有与之对应的真实标签。所有$L_t$相加就得到了最终的Loss $L$。在反向传播中我们需要计算$\frac{dL}{dW}$，而$L$又会回溯到每一个时间步的损失，然后每一时间步又会各自计算出当下$\frac{dL_t}{dW}$，其总和就是权重$W$的最终梯度。</p>
<h2 id="Many-to-one"><a href="#Many-to-one" class="headerlink" title="Many to one"></a>Many to one</h2><p><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/6.png" alt="Loading..."><br>此种结构通常用于情感分析等问题。我们会根据网络的最终$h_T$做出决策，因为其整合了序列中包含的所有情况。</p>
<h2 id="One-to-many"><a href="#One-to-many" class="headerlink" title="One to many"></a>One to many</h2><p><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/7.png" alt="Loading..."><br>此种结构通常用于自动生成图片描述等问题。</p>
<h2 id="Sequence-to-sequence"><a href="#Sequence-to-sequence" class="headerlink" title="Sequence to sequence"></a>Sequence to sequence</h2><p><strong>Many-to-one+One-to-many</strong><br><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/8.png" alt="Loading..."><br>此种结构通常用于机器翻译。编码阶段会接收到一个不定长的输入序列（如一个句子），然后整个句子会被编码器网络最终的隐层状态编码成一个单独的向量。解码阶段每一个时间步下会做出一个预测，将其还原成一个句子。</p>
<h1 id="示例：字符级别语言模型"><a href="#示例：字符级别语言模型" class="headerlink" title="示例：字符级别语言模型"></a>示例：字符级别语言模型</h1><p>现在有vocabulary：[h, e, l, o]，example training sequence：“hello”。我们希望输入前一个字母后网络能够预测出下一个字母是什么。<br>训练过程如下：<br><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/9.png" alt="Loading..."><br>我们可以看到第一个时间步输入“h”，应该输出“e”，但预测结果score最高的是“o”。</p>
<p>测试过程如下所示：<br><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/10.png" alt="Loading..."><br>在测试时，一次输入一个样本字符，将输出的字符反馈给模型（这里先不用去看数值，虽然h后面o的可能性最大，但是这里假设就是e）。</p>
<p>接下来我们就要利用Loss来backpropagation修正整个网路，RNN通过时间进行反向传播过程如下图所示：<br><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/11.png" alt="Loading..."><br>由上图可以看出如果直接是在全局计算的话，会发现显存或内存不够，而且计算过程十分耗时，因为每计算一次梯度都必须做一次前向计算，遍历所有的训练集，然后反向传播每次也会遍历一遍训练集。</p>
<p>在实际中人们通常采用一种近似方法，我们称之为延时间的截断（Truncated）反向传播方法。在训练模型时，前向计算若干步（如100），仅计算这个子序列的Loss，然后沿子序列反向传播并计算梯度更新参数，如下图所示。<br><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/12.png" alt="Loading..."><br>重复上述batch的计算过程（进入下一个100步），前向传播与第一个batch无异（需导入上一个batch最后得到的隐藏状态$h_t$），但是在计算梯度时，我们仅根据第二批数据反向传播误差，仅更新该batch中的参数（如下图所示）。<br><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/13.png" alt="Loading..."><br>Andrej Karpathy写了一个Vanilla RNN简单的示例程序：<a href="https://gist.github.com/karpathy/d4dee566867f8291f086" target="_blank" rel="external">min-char-rnn.py</a>，顺便给大家推荐该代码作者写的详解 <a href="https://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank" rel="external">karpathy’blog</a>。</p>
<h1 id="RNN的可解释性"><a href="#RNN的可解释性" class="headerlink" title="RNN的可解释性"></a>RNN的可解释性</h1><p>[Karpathy, Johnson, and Fei-Fei: Visualizing and Understanding Recurrent Networks, ICLR Workshop 2016]<br><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/14.png" alt="Loading..."><br>该论文中作者训练了一个字符层级的语言模型循环神经网络，然后从隐藏向量中选取一个元素，通过一个序列过程来看这个隐藏向量的值，试图了解这些不同隐藏状态正在寻找的东西。<br><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/15.png" alt="Loading..."><br>从向量中选择一个元素，然后让句子继续向前运行通过训练好的模型，接下来每个字符的颜色对应于隐藏矢量在读取序列时的每个时间步长的单个标量元素的大小。</p>
<h1 id="图像标注问题"><a href="#图像标注问题" class="headerlink" title="图像标注问题"></a>图像标注问题</h1><p>[Karpathy A, Li F F. Deep visual-semantic alignments for generating image descriptions, CVPR 2015]<br><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/16.png" alt="Loading..."><br>我们希望输入一个图像，然后输出自然语言的图像语义信息。</p>
<p>模型中有一部分卷积神经网络用来处理输入的图像信息，它将产生图像的特征向量，然后输入到循环神经网络语言模型的第一个时间步中，一次一个地生成标题的单词。</p>
<p><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/17.png" alt="Loading..."><br>我们把输入图像输入到卷积神经网络中，但是我们不是使用这个图像网络模型中最后得到的softmax值，而是使用模型末端的4096维向量，我们用这个向量来概述整个图像的内容。</p>
<p><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/18.png" alt="Loading..."><br>当我们讨论递归神经网络语言模型时，我们需要知道模型的第一个初始化输入，来告诉它开始生成文字。本论文中作者给它了一些特殊的开始记号。在之前的递归神经网络语言模型中我们已经了解了这些矩阵的计算公式，即把当前时间步的输入以及前一个时间步的隐藏状态结合到下一个时间步的隐藏状态。但我们现在还需要添加图片信息，需要用完全不同的方法来整合这些信息，一个简单的方式是加入第三个权重矩阵，它在每个时间步中添加图像信息来计算下一个隐藏状态（如上图所示）。<br><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/19.png" alt="Loading..."><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/20.png" alt="Loading..."><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/21.png" alt="Loading..."><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/22.png" alt="Loading..."><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/23.png" alt="Loading..."><br>上面五幅图演示了生成句子的过程。</p>
<p>现在我们需要计算词汇表中所有scores的分布，在这里我们的词汇表是类似所有英语词汇的东西，所以他可能会相当大，我们将从分布中采样并在下一次时间步时当做输入传入。依次重复上述步骤，我们将生成完整的句子。一旦我们采样到特殊停止标记（类似于句号）就停止生成。在训练时，我们在每个标题末尾都放上结束的标志，这样在训练过程中结束标记就出现在序列的末尾。在测试时，它倾向于在完成生成句子后对这些结束标记进行采样。</p>
<h1 id="Attention机制"><a href="#Attention机制" class="headerlink" title="Attention机制"></a>Attention机制</h1><p><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/24.png" alt="Loading..."><br>当我们生成这个图片标题的文字时，我们允许模型来引导它们的注意到图像不同的部分。<br><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/25.png" alt="Loading..."><br>通常的做法是，相比于产生一个单独的向量来整合整个图像，该方法的卷积神经网络倾向于产生由向量构成的网络给每幅图片中特殊的地方都用一个向量表示。当我们在前向传播时，除了在每一时间步中对词汇表进行采样外，还会在图像中想要查看的位置上产生一个分布。图像位置的分布可以看成是一种模型在训练过程中应该关注哪里的张量。因此第一个隐藏状态$h_0$计算在图片位置上的分布$a_1$，它将会回到向量集合，给出一个概要向量$z_1$，把注意力集中在图像的某一部分上。<br><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/26.png" alt="Loading..."><br>现在这个概要向量得到了反馈，作为神经网络下一时间步的额外输入。接着$h_1$将产生两个输出，一个是我们在词汇表上的分布$d_1$，一个是图像位置的分布$a_2$，整个过程将会继续下去，它在每个时间步都会做这两件不同的事情。</p>
<p>Ps：软注意力机制采用的是加权组合，所有图像位置中的所有特征。硬注意力机制中，我们限制模型在每一步只选择一个位置来观察图片。在硬注意力的情况下选择图像的位置有点复杂，因为这不是一个可微函数，所以需要使用一些比vanilla反向传播算法高级一点的算法，以便能够在那样的情况下训练模型。</p>
<h1 id="视觉问答：RNNs-with-Attention"><a href="#视觉问答：RNNs-with-Attention" class="headerlink" title="视觉问答：RNNs with Attention"></a>视觉问答：RNNs with Attention</h1><p><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/36.png" alt="Loading..."><br><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/27.png" alt="Loading..."><br>这是一个多对一的情形（选出正确的答案）。我们的模型需要将自然语言序列作为输入，我们可以设想针对输入问题的每个元素，建立一个递归神经网络，从而将输入问题概括为一个向量。然后我们可以用CNN将图像也概括为一个向量。现在把CNN得出的向量和输入问题的向量结合，通过RNN编程来预测答案的概率分布。有时候会将soft spatial attention结合到视觉问答中，所以在这里可以看到这个模型在试图确定这些问题的答案时它在图像上仍具有spatial attention。</p>
<p>Q：如何将编码图像向量和编码问题向量组合起来？<br>A：最简单的一种做法是将他们连接起来然后粘贴进FC中。有时也会用一些高级的方法，即在这两个向量之间做乘法从而得到更为强大的函数。</p>
<h1 id="Multilayers-RNNs"><a href="#Multilayers-RNNs" class="headerlink" title="Multilayers RNNs"></a>Multilayers RNNs</h1><p><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/28.png" alt="Loading..."><br>如上所示是一个三层循环神经网络结构图，现在将输入传进模型，然后在第一层的RNN中产生一系列的隐藏状态。在我们运行了RNN的一层之后得到了所有的隐藏状态序列。我们可以将这些隐藏状态序列作为第二层RNN的输入序列，以此类推。<br>（RNN一般2-4层就足够了）</p>
<h1 id="Vanilla-RNN-梯度流"><a href="#Vanilla-RNN-梯度流" class="headerlink" title="Vanilla RNN 梯度流"></a>Vanilla RNN 梯度流</h1><p><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/29.png" alt="Loading..."><br>上图中可以看出隐藏状态$h_t$的计算过程。计算梯度时，我们会得到$\frac{dLoss}{dh_t}$，最后我们需要计算的是$\frac{dLoss}{dh_{t-1}}$。当我们进行反向传播时，梯度会沿红线反向流动。但是当反向传播流过矩阵乘法门时，实际上是用权重矩阵的转置来做矩阵乘法，这意味着每一次BP经过一个vanilla RNN单元时就需要和权重矩阵相乘一次。<br><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/30.png" alt="Loading..."><br>当我们把很多网络单元连接成一个序列，梯度反向流动穿过一些这样的层时，都要乘以一个权重矩阵的转置，这意味着最终$h_0$的梯度表达式将会包含很多权重矩阵因子。（再强调一下，每一个单元的$W$是相同的）</p>
<p>为了便于理解，我们可以将权重矩阵简化为标量。假如我们有一些标量，我们不断地对同一个数值与这些标量做乘法，当有几百时间步时，情况将非常糟糕。在标量的情形中，它要么在这些标量绝对值大于1时发生梯度爆炸，要么当这些标量绝对值小于1时发生梯度消失。唯一能够让这不发生的情况是这些标量值刚好是1。延伸到矩阵的情况时，标量的绝对值替换为权重矩阵的最大奇异值。</p>
<p><strong>解决梯度爆炸的方法</strong>：梯度截断<br>判断梯度的L2范数是否大于某个值。<br><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/31.png" alt="Loading..."></p>
<p><strong>解决梯度消失的方法</strong>：改变RNN结构<br>引出了下面介绍的LSTM。</p>
<h1 id="长短期记忆网络（LSTM）"><a href="#长短期记忆网络（LSTM）" class="headerlink" title="长短期记忆网络（LSTM）"></a>长短期记忆网络（LSTM）</h1><p><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/32.png" alt="Loading..."><br>如上图所示，LSTM每个时间步都维持两个隐藏状态。我们称$h_t$为隐藏状态，$c_t$为单元状态，$c_t$相当于保留在LSTM内部的隐藏状态，不会完全暴露到外部去。首先我们传入两个输入来计算四个门i、f、o、g，使用这些门来更新单元状态$c_t$，然后将这些单元状态作为参数来计算下一时间步中的隐藏状态。</p>
<p><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/33.png" alt="Loading..."><br>将上一时间步的隐藏状态和当前时间步的输入堆叠在一起，然后乘上一个非常大的权重矩阵w，计算得到四个不同的门向量，每个门向量的大小和隐藏状态一样。</p>
<p><strong>i代表输入门</strong>，表示LSTM要接受多少新的输入信息；<strong>f是遗忘门</strong>，表示要遗忘多少之前的单元记忆（上一时间步的记忆信息）；<strong>o是输出门</strong>，表示我们要展现多少信息给外部；<strong>G是门中门</strong>，表示我们有多少信息要写到输入单元中去。四个门中i、f、o都用了sigmoid，这意味着输出值都在0和1之间。G用了tanh函数，这意味着输出都在-1到1之间。</p>
<p>从上图公式中我们可以看出单元状态是经过遗忘门逐项相乘的。<strong>遗忘门</strong>可以看做是由0和1组成的向量，F中0表示我们忘记这个单元状态中的这个元素值，1说明我们想要记住这个单元状态中的这个值。使用遗忘门来断开部分单元状态的值后，我们接下来需要<strong>输入门</strong>和<strong>门中门</strong>逐元素相乘。i是由0和1构成的向量，对于单元状态的每个元素值，i的值为1表示我们想要保留单元状态的那个元素，i的值为0表示我们不想保留单元状态对应的那个元素。<strong>门中门</strong>中的这些值是当前时间步中我们可能会写入到单元状态中去的候选值。单元状态$c_t$在每个时间步中都可以被加一或减一。也就是说在单元状态的内部，我们可以保留或者遗忘之前的状态。所以可以把$c_t$中的每个元素看作是小的标量计数器。</p>
<p>$c_t$经过tanh后被压缩到0~1，再用输出门逐元素相乘。<strong>输出门</strong>告诉我们对于单元状态中的每个元素，当我们在此时间步计算外部的隐藏状态时，是否希望单元状态中的此元素暴露出去。</p>
<p><strong>LSTM示意图</strong>：<br><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/34.png" alt="Loading..."><br>我们通过传输进来的单元获得了上游梯度$\frac{dLoss}{dc_t}$，然后通过加法运算向后进行方向传播，这个加法运算仅仅是将上游的梯度复制到这两个分支中，这样上游梯度直接被复制并且通过与遗忘门元素相乘的方式贯穿了反向传播过程。此方法的优点在于这里与<strong>遗忘门f</strong>相乘是矩阵元素相乘而不是矩阵相乘；另一点是矩阵元素相乘可能会在不同的时间点乘以一个不同的<strong>遗忘门</strong>（更容易避免梯度消失和梯度爆炸的问题），而在vanilla RNN中我们是不断地乘以相同的权重矩阵；最后一个优点是梯度从最后一个隐藏状态$h_T$传递到$c_0$只会经过一个tanh。</p>
<p><img src="https://raw.githubusercontent.com/KunBB/MarkdownPhotos/master/CS231n_10/35.png" alt="Loading..."><br>通过单元状态进行反向传播的路径是一种梯度高速公路，使梯度相对畅通无阻地从模型最末端的损失函数返回到模型最开始的初始单元状态（与ResNet类似）。</p>
<p>Q：<strong>遗忘门f</strong>是一个0~1的数，是否也会导致出现梯度消失的问题？<br>A：人们常会初始化遗忘门的偏置参数，进而使遗忘门总是非常接近于1。</p>
<p>这里推荐一篇论文：[LSTM: A Search Space Odyssey Greff et al., 2015]，这篇论文详细研究了LSTM更新方程的每一个部分。</p>
<hr>
<font color="red" size="6">**本博客与https://xuyunkun.com同步更新**</font>

      
    </div>
    
    
    

    

    
      <div>
        <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
  <div>Donate comment here</div>
  <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
    <span>Donate</span>
  </button>
  <div id="QR" style="display: none;">

    
      <div id="wechat" style="display: inline-block">
        <img id="wechat_qr" src="/wechatpay.jpg" alt="Yunkun Xu WeChat Pay"/>
        <p>WeChat Pay</p>
      </div>
    

    
      <div id="alipay" style="display: inline-block">
        <img id="alipay_qr" src="/alipay.jpg" alt="Yunkun Xu Alipay"/>
        <p>Alipay</p>
      </div>
    

    

  </div>
</div>

      </div>
    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Artificial-Intelligence/" rel="tag"># Artificial Intelligence</a>
          
            <a href="/tags/Deep-Leanring/" rel="tag"># Deep Leanring</a>
          
            <a href="/tags/Machine-Learning/" rel="tag"># Machine Learning</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/09/28/CS231n Lecture 9 CNN Architectures Summary/" rel="next" title="CS231n Lecture 9 CNN Architectures Summary">
                <i class="fa fa-chevron-left"></i> CS231n Lecture 9 CNN Architectures Summary
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="lv-container" data-id="city" data-uid="MTAyMC8zMDg2NC83NDEz"></div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          
            <img class="site-author-image" itemprop="image"
              src="https://timgsa.baidu.com/timg?image&amp;quality=80&amp;size=b9999_10000&amp;sec=1505221430290&amp;di=5d6a88d013890d4f520618b024b4aaed&amp;imgtype=0&amp;src=http%3A%2F%2Fimg3.duitang.com%2Fuploads%2Fitem%2F201601%2F03%2F20160103085338_eyBCL.jpeg"
              alt="Yunkun Xu" />
          
            <p class="site-author-name" itemprop="name">Yunkun Xu</p>
            <p class="site-description motion-element" itemprop="description"></p>
        </div>

        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
            
              <a href="/archives/">
            
                <span class="site-state-item-count">10</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">6</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">26</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#RNN网络结构"><span class="nav-number">1.</span> <span class="nav-text">RNN网络结构</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Many-to-many"><span class="nav-number">1.1.</span> <span class="nav-text">Many to many</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Many-to-one"><span class="nav-number">1.2.</span> <span class="nav-text">Many to one</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#One-to-many"><span class="nav-number">1.3.</span> <span class="nav-text">One to many</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Sequence-to-sequence"><span class="nav-number">1.4.</span> <span class="nav-text">Sequence to sequence</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#示例：字符级别语言模型"><span class="nav-number">2.</span> <span class="nav-text">示例：字符级别语言模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#RNN的可解释性"><span class="nav-number">3.</span> <span class="nav-text">RNN的可解释性</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#图像标注问题"><span class="nav-number">4.</span> <span class="nav-text">图像标注问题</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Attention机制"><span class="nav-number">5.</span> <span class="nav-text">Attention机制</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#视觉问答：RNNs-with-Attention"><span class="nav-number">6.</span> <span class="nav-text">视觉问答：RNNs with Attention</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Multilayers-RNNs"><span class="nav-number">7.</span> <span class="nav-text">Multilayers RNNs</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Vanilla-RNN-梯度流"><span class="nav-number">8.</span> <span class="nav-text">Vanilla RNN 梯度流</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#长短期记忆网络（LSTM）"><span class="nav-number">9.</span> <span class="nav-text">长短期记忆网络（LSTM）</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  本站访客数:<span id="busuanzi_value_site_uv"></span>
</span>
</div>

<div class="powered-by">
 | 
<i class="fa fa-bullseye"></i><span id="busuanzi_container_site_pv">
  本站总访问量<span id="busuanzi_value_site_pv"></span>次
</span>
</div>

<div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Yunkun Xu</span>

  
</div>





        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>

  
  <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  

  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>


  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  




	





  





  
    <script type="text/javascript">
      (function(d, s) {
        var j, e = d.getElementsByTagName(s)[0];
        if (typeof LivereTower === 'function') { return; }
        j = d.createElement(s);
        j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
        j.async = true;
        e.parentNode.insertBefore(j, e);
      })(document, 'script');
    </script>
  








  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.4.js"></script>
  <script>AV.initialize("QhaBjkfW4URLRbhgJHxDwlLS-gzGzoHsz", "lMWD4RO6uM9qzr8tTOVVb70w");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->



  

  

  
  


  

  

  
  
</body>
</html>

<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/love.js"></script>