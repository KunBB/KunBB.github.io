<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Reinforcement Learning：An Introduction Chapter1 学习笔记]]></title>
    <url>%2F2018%2F09%2F19%2FReinforcement%20Learning%EF%BC%9AAn%20Introduction%20Chapter1%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[Chapter 1: Introduction人类与环境进行互动，学习环境如何响应我们的行为，并试图通过自身行为影响将来发生的事，这就是一种交互式的学习方式，是人类获取知识的主要来源，同时也是几乎所有学习和智能化理论的基本思想。强化学习正是一种从交互中学习的计算方法，它更侧重于从交互中进行目标导向的学习方式，而不是其他的机器学习方式。 1.1 Reinforcement Learning强化学习特征强化学习就是学习该做什么，如何将情境映射到动作从而最大化奖励信号。试错搜索（trial-and-error search）和延迟奖励（delayed reward）是强化学习两个最重要的显著特征，即：· 学习者不会被告知需要采取哪些行动，而是必须通过尝试来发现哪些行动可以产生最大的回报；· 当前行动不仅影响即时奖励，还会影响下一个状态，以及后续奖励。 强化学习与其他人工智能技术的区别监督学习是从一组有标记的训练集中进行学习，目的是让系统归纳与推断其响应，使其在训练集中不存在的样例下也能正确做出相应动作。监督学习是一种重要的学习方式，但其不足以从交互中学习。在交互问题中获取正确而又代表所有情况的所期望行为的样例是不切实际的。在未知领域，智能体必须能够从自身经验中学习才能习得最有益的行为动作。 非监督学习通常是寻找隐藏在未标记数据集合中的某种结构。虽然强化学习也不需要带有正确标记的例子，但它的目标是最大化奖励信号，而不是试图找到隐藏的结构。当然，找到智能体学习经验中的隐藏结构也是有用的，但这并不是最终目标。 强化学习的挑战 Reference:[1] 《reinforcement learning：an introduction》第一章《The Reinforcement Learning Problem》总结：https://blog.csdn.net/mmc2015/article/details/74931291]]></content>
      <categories>
        <category>Reinforcement Learning</category>
      </categories>
      <tags>
        <tag>Reinforcement Learning</tag>
        <tag>Artificial Intelligence</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Qt+webservice的多线程实现]]></title>
    <url>%2F2018%2F08%2F13%2FQt%2Bwebservice%E7%9A%84%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[项目使用Qt搭建了一个数据库软件，需要远程访问公司的MES系统，使用webservice技术进行通信并以XML格式传输数据，为了使网络监听过程中不影响主线程程序的正常运行，我们需要将webservice相关功能放在新开的独立线程中。 本项目使用的是QtCreator(Qt5.5.0)+VisualStudio2013+gSOAP2.8搭建。其他版本只要版本是正确对应的，都大同小异。 WebService相关概念参见参考文献[3]。 WebService是一种跨编程语言和跨操作系统平台的远程调用技术。所谓跨编程语言和跨操作平台，就是说服务端和和客户端的搭建平台与编程语言可以都不相同。所谓远程调用，就是一台计算机a上 的一个程序可以调用到另外一台计算机b上的一个对象的方法。 其实可以从多个角度来理解WebService，从表面上看，WebService就是一个应用程序向外界暴露出一个能通过Web进行调用的API，也就是说能用编程的方法通过 Web来调用这个应用程序。我们把调用这个WebService的应用程序叫做客户端，而把提供这个WebService的应用程序叫做服务端。从深层次看，WebService是建立可互操作的分布式应用程序的新平台，是一个平台，是一套标准。它定义了应用程序如何在Web上实现互操作性，你可以用任何 你喜欢的语言，在任何你喜欢的平台上写Webservice ，只要我们可以通过Webservice标准对这些服务进行查询和访问。 WebService平台需要一套协议来实现分布式应用程序的创建。任何平台都有它的数据表示方法和类型系统。要实现互操作性，WebService平台必须提供一套标准的类型系统，用于沟通不同平台、编程语言和组件模型中的不同类型系统。Webservice平台必须提供一种标准来描述Webservice，让客户可以得到足够的信息来调用这个Webservice。最后，我们还必须有一种方法来对这个Webservice进行远程调用,这种方法实际是一种远程过程调用协议(RPC)。为了达到互操作性，这种RPC协议还必须与平台和编程语言无关。 XML+XSD,SOAP和WSDL就是构成WebService平台的三大技术。 XML+XSDWebService采用HTTP协议传输数据，采用XML格式封装数据(即XML中说明调用远程服务对象的哪个方法，传递的参数是什么，以及服务对象的 返回结果是什么)，XML是WebService平台中表示数据的格式，其优点在于它既是平台无关又是厂商无关的。XML解决了数据表示的问题，但它没有定义一套标准的数据类型，更没有说怎么去扩展这套数据类型。例如整形数到底代表什么？16位，32位，64位？这些细节对实现互操作性很重要。XML Schema(XSD)就是专门解决这个问题的一套标准。它定义了一套标准的数据类型，并给出了一种语言来扩展这套数据类型。WebService平台就是用XSD来作为其数据类型系统的。当你用某种语言(如VB.NET或C#)来构造一个Webservice时，为了符合WebService标准，所有你使用的数据类型都必须被转换为XSD类型。你用的工具可能已经自动帮你完成了这个转换，但你很可能会根据你的需要修改一下转换过程。 SOAPSOAP是”简单对象访问协议”，SOAP协议 = HTTP协议 + XML数据格式。WebService通过HTTP协议发送请求和接收结果时，发送的请求内容和结果内容都采用XML格式封装，并增加了一些特定的HTTP消息头，以说明HTTP消息的内容格式，这些特定的HTTP消息头和XML内容格式就是SOAP协议。SOAP提供了标准的RPC方法来调用WebService。SOAP协议定义了SOAP消息的格式，SOAP协议是基于HTTP协议的，SOAP也是基于XML和XSD的，XML是SOAP的数据编码方式。打个比喻：HTTP就是普通公路，XML就是中间的绿色隔离带和两边的防护栏，SOAP就是普通公路经过加隔离带和防护栏改造过的高速公路。 WSDL好比我们去商店买东西，首先要知道商店里有什么东西可买，然后再来购买，商家的做法就是张贴广告海报。 WebService也一样，WebService客户端要调用一个WebService服务，首先要有知道这个服务的地址在哪，以及这个服务里有什么方法可以调用，所以WebService务器端首先要通过一个WSDL文件来说明自己家里有啥服务可以对外调用，服务是什么（服务中有哪些方法，方法接受的参数是什么，返回值是什么），服务的网络地址用哪个url地址表示，服务通过什么方式来调用。WSDL(Web Services Description Language)就是这样一个基于XML的语言，用于描述WebService及其函数、参数和返回值。它是WebService客户端和服务器端都能理解的标准格式。因为是基于XML的，所以WSDL既是机器可阅读的，又是人可阅读的，这将是一个很大的好处。一些最新的开发工具既能根据你的Webservice生成WSDL文档，又能导入WSDL文档，生成调用相应WebService的代理类代码。WSDL文件保存在Web服务器上，通过一个url地址就可以访问到它。客户端要调用一个WebService服务之前，要知道该服务的WSDL文件的地址。 WebService服务提供商可以通过两种方式来暴露它的WSDL文件地址：1.注册到UDDI服务器，以便被人查找；2.直接告诉给客户端调用者。 gSOAP总结gsoap概念：是一种能够把C/C++语言的接口转换成基于soap协议的webservice服务的工具。从官网的说明文档可知gSOAP可以为我们完成以下工作： 1、自动生成C和C++源代码，以使用和部署XML、JSON REST API以及SOAP/XML API；2、使用gSOAP的快速XML流处理模型进行XML解析和验证，实现实现可移植的快速的和精简的API，每秒处理10K+消息仅需几KB代码和数据；3、将WSDL转换为有效的C或C++源代码以使用或部署XML Web服务；4、将XML schemas(XSD)转换为高效的C或C++源代码，以使用gSOAP全面的XML schemas功能覆盖来使用或部署XML REST API；5、为WSDL和/或XSD定义的大型复杂XML规范生成高效的C和C ++代码，例如eBay，ONVIF，HL7，FHIR，HIPAA 5010，CDISC，XMPP XEP，TR-069，AWS，EWS，ACORD，ISO 20022和SWIFT，FixML，XBRL，OTA，IATA NDC，FedEx等（您甚至可以将多个组合在一起）；6、安全的XML处理过程：gSOAP不容易受到大部分XML攻击手段的攻击；7、使用强大的XML数据绑定准确地序列化XML中的C和C++数据，这有助于通过静态类型快速开发类型安全的API，以避免运行时错误；8、在WSDL和XSD文件上使用wsdl2h选项-O2或-O4进行“schema slicing”，通过自动删除未使用的schema类型（WSDL和XSD根目录中无法访问的类型）来优化XML代码库的大小；9、使用和部署JSON REST API；10、使用SAML令牌安全地使用HTTP/S，WS-Security和WS-Trust来使用和部署API;11、使用测试信使CLI测试您的SOAP/XML API，它会自动生成基于WSDL的完整和随机化的SOAP/XML消息（使用带有选项-g的wsdl2h和soapcpp2）来测试Web服务API和客户端；12、使用gSOAP Apache模块在Apache Web服务器中部署API，在IIS中使用gSOAP ISAPI扩展部署API；13、使用gSOAP cURL插件和gSOAP WinInet插件来使用API；14、符合XML的行业标准，包括XML REST和SOAP，WSDL，MIME，MTOM，DIME，WS-Trust，WS-Security（集成了WS-Policy和WS-SecurityPolicy），WS-ReliableMessaging，WS-Discovery，WS-Addressing等； gSOAP简介gSOAP一种跨平台的开源的C/C++软件开发工具包。生成C/C++的RPC代码，XML数据绑定，对SOAP Web服务和其他应用形成高效的具体架构解析器，它们都受益于一个XML接口。 这个工具包提供了一个全面和透明的XML数据绑定解决方案，Autocoding节省大量开发时间来执行SOAP/XML Web服务中的C/C++。此外，使用XML数据绑定大大简化了XML自动映射。应用开发人员不再需要调整应用程序逻辑的具体库和XML为中心的数据。 gSOAP结构使用gSOAP首先需要用到了两个工具就是../gsoap-2.8/gsoap/bin/win32/wsdl2h.exe和../gsoap-2.8/gsoap/bin/win32/soapcpp2.exe，用于自动生成包含接口的c/c++源文件。 wsdl2h.exe该工具可以根据输入的wsdl或XSD或URL产生相应的C/C++形式的.h供soapcpp2.exe使用。示例如下： 新建一个文件夹，将wsdl2h.exe(和.wsdl文件)放入，命令行进入当前路径后输入以下命令：1234wsdl2h [options] XSD and WSDL files ...wsdl2h -o file.h file1.wsdlwsdl2h -o file.h http://www.genivia.com/calc.wsdl 根据WSDL自动生成file.h头文件，以供soapcpp2.exe使用。 wsdl2h主要的运行选项如下： 选项 描述 -a 对匿名类型产生基于顺序号的结构体名称 -b 提供单向响应消息的双向操作（双工） -c 生成c代码 -c++ 生成c++代码 -c++11 生成c++11代码 -d 使用DOM填充xs：any和xsd：anyType元素 -D 使用指针使具有默认值的属性成员可选 -e 不要限定枚举名称，此选项用于向后兼容gSOAP 2.4.1及更早版本，该选项不会生成符合WS-I Basic Profile 1.0a的代码。 -f 为schema扩展生成平面C++类层次结构 -g 生成全局顶级元素声明 -h 显示帮助信息 -I path 包含文件时指明路径，相当于#import -i 不导入（高级选项） -j 不生成SOAP_ENVHeader和SOAP_ENVDetail定义 -k 不生成SOAP_ENV__Header mustUnderstand限定符 -l 在输出中包含许可证信息 -m 使用xsd.h模块导入基元类型 -N name 用name 来指定服务命名空间的前缀 -n name 用name 作为命名空间的前缀取代缺省的ns -O1 通过省略重复的选择/序列成员来优化 -O2 优化-O1并省略未使用的模式类型（从根目录无法访问） -o file 输出文件名 -P 不要创建从xsd__anyType继承的多态类型 -p 创建从base xsd__anyType继承的多态类型，当WSDL包含多态定义时，会自动执行此操作 -q name 使用name作为所有声明的C++命名空间 -R 在WSDL中为REST绑定生成REST操作 -r host[:port[:uid:pwd]] 通过代理主机，端口和代理凭据连接 -r:uid:pwd 连接身份验证凭据（验证身份验证需要SSL） -s 不生成STL代码（没有std :: string和没有std :: vector） -t file 使用类型映射文件而不是默认文件typemap.dat -U 将Unicode XML名称映射到UTF8编码的Unicode C/C++标识符 -u 不产生工会unions -V 显示当前版本并退出 -v 详细输出 -W 抑制编译器警告 -w 始终在响应结构中包装响应参数 -x 不生成_XML any/anyAttribute可扩展性元素 -y 为结构和枚举生成typedef同义词 soapcpp2.exe该工具是一个根据.h文件生成若干支持webservice代码文件生成工具，生成的代码文件包括webservice客户端和服务端的实现框架，XML数据绑定等，具体说明如下： 新建一个文件夹，将soapcpp2.exe和.h文件放入，命令行进入当前路径后输入以下命令：1234soapcpp2 [options] header_file.hsoapcpp2 mySoap.hsoapcpp2 -c -r -CL calc.h 会生成如下c类型文件： 使用命令-i会生成如下c++类型文件： 文件 描述 soapStub.h 根据输入的.h文件生成的数据定义文件，一般我们不直接引用它 soapH.h 所有客户端服务端都应包含的主头文件 soapC.cpp 指定数据结构的序列化和反序列化方法 soapClient.cpp 用于远程操作的客户端存根例程 soapServer.cpp 服务框架例程 soapClientLib.cpp 客户端存根与本地静态(反)序列化器结合使用 soapServerLib.cpp 服务框架与本地静态(反)序列化器结合使用 soapXYZProxy.h 使用选项-i：c++服务端对象(与soapC.cpp和soapXYZProxy.cpp链接) soapXYZProxy.cpp 使用选项-i：客户端代码 soapXYZService.h 使用选项-i：server对象(与soapC.cpp和soapXYZService.cpp链接) soapXYZService.cpp 使用选项-i：服务端代码 .xsd ns.XSD由XML Schema生成，ns为命名空间前缀名，我们可以看看是否满足我们的协议格式（如果有此要求） .wsdl ns.wsdl由WSDL描述生成 .xml 生成了几个SOAP/XML请求和响应文件。即满足webservice定义的例子message(实际的传输消息)，我们可以看看是否满足我们的协议格式(如果有此要求) .nsmap 根据输入soapcpp2.exe的头文件中定义的命名空间前缀ns生成ns.nsmap，该文件包含可在客户端和服务端使用的命名空间映射表 soapcpp的主要运行选项如下： 选项 描述 -1 生成SOAP 1.1绑定 -2 生成SOAP 1.2绑定 -0 没有SOAP绑定，使用REST -C 仅生成客户端代码 -S 仅生成服务端代码 -T 生成服务端自动测试代码 -Ec 为深度数据复制生成额外的例程 -Ed 为深度数据删除生成额外的例程 -Et 使用walker函数为数据遍历生成额外的例程 -L 不生成soapClientLib / soapServerLib -a 使用SOAPAction和WS-Addressing来调用服务端操作 -A 要求SOAPAction调用服务端操作 -b 序列化字节数组char [N]为字符串 -c 生成纯C代码 -d 保存到指定目录中 -e 生成SOAP RPC编码样式绑定 -f N 多个soapC文件，每个文件有N个序列化程序定义（N≥10） -h 打印一条简短的用法消息 -i 生成从soap struct继承的服务代理类和对象 -j 生成可以共享soap结构的C++服务代理类和对象 -I 包含其他文件时使用，指明 &lt; path &gt; (多个的话，用`:’分割)，相当于#import ，该路径一般是gSOAP目录下的import目录，该目录下有一堆文件供soapcpp2生成代码时使用 -l 生成可链接模块（实验） -m 为MEX编译器生成Matlab代码 -n 用于生成支持多个客户端和服务器端 -p 生成的文件前缀采用&lt; name &gt; ，而不是缺省的 “soap” -q 使用name作为c++所有声明的命名空间 -r 生成soapReadme.md报告 -s 生成的代码在反序列化时，严格检查XML的有效性 -t 生成的代码在发送消息时，采用xsi:type方式 -u 通过抑制XML注释来取消注释WSDL / schema输出中的注释 -V 显示当前版本并退出 -v 详细输出 -w 不生成WSDL和schema文件 -x 不生成示例XML消息文件 -y 在示例XML消息中包含C / C ++类型访问信息 实例介绍功能介绍1、客户端能够向服务端发送字符串数据；2、服务端能够接收到客户端发送的字符串数据；3、服务端对字符串数据解析、查重并录入数据库；4、软件窗口显示连接状态。 最终效果如下所示：点击“开始连接”按钮： 从客户端接收到一组数据后： 实例步骤1. 生成源代码由于没有.wsdl文件，因此我们跳过wsdl2h.exe这一步骤，手动编写供soapcpp2.exe使用的头文件mySoap.h：123456//gsoap ns service name: sendMsg//gsoap ns service style: rpc//gsoap ns service encoding: encoded//gsoap ns service namespace: urn:sendMsgint ns__sendMsg(char* szMsgXml,struct nullResponse&#123;&#125; *out); 新建文件夹，将soapcpp2.exe和mySoap.h放入，打开命令后进入该目录下，运行命令soapcpp2 mySoap.h，生成如下文件： 2. 客户端程序编写在QtCreator中向客户端工程目录添加文件sendMsg.nsmap、soapH.h、soapStub.h、stdsoap2.h、soapC.cpp、soapClient.cpp、stdsoap2.cpp(stdsoap2.h和stdsoap2.cpp位于文件夹../gsoap-2.8/gsoap)。 客户端项目构建的是一个控制台程序，因此直接在main函数里进行编写代码：12345678910111213141516171819202122232425262728293031#include &lt;QCoreApplication&gt;#include "stdio.h"#include "gservice.nsmap"#include "soapStub.h"int main(int argc, char *argv[])&#123; QCoreApplication a(argc, argv); printf("The Client is runing...\n"); struct soap *CalculateSoap = soap_new(); char server_addr[] = "127.0.0.1:8080"; // url地址，IP号+设备端口号 char* data = "flange,6,7,8,9,10,11,12,13"; // 所需传递的数据 nullResponse result; // 用于sendMsg的空返回值 int iRet = soap_call_ns__sendMsg(CalculateSoap,server_addr,NULL,data,&amp;result); // 调用之前定义的ns__sendMsg方法(即服务端提供的方法) if ( iRet == SOAP_ERR)&#123; printf("Error while calling the soap_call_ns__sendmsg"); &#125; else &#123; printf("Calling the soap_call_ns__add success。\n"); &#125; soap_end(CalculateSoap); soap_done(CalculateSoap); return a.exec();&#125; 3. 服务端程序编写在QtCreator中向服务端工程目录添加文件sendMsg.nsmap、soapH.h、soapStub.h、stdsoap2.h、soapC.cpp、soapServer.cpp、stdsoap2.cpp。 由于服务端网络通信功能需要不断对端口进行监听，因此为避免影响软件其他功能的运行，在此需要新开一条线程。项目头文件源码如下：socketconnect.h:12345678910111213141516171819202122232425262728293031323334353637#ifndef SOCKETCONNECT_H#define SOCKETCONNECT_H#include &lt;QWidget&gt;#include &lt;QDebug&gt;#include &lt;QVector&gt;#include "webservice_thread.h" // 多线程头文件#include &lt;QMessageBox&gt;namespace Ui &#123;class SocketConnect;&#125;class SocketConnect : public QWidget&#123; Q_OBJECTpublic: void setDbconn(QSqlDatabase *dbconn); // 主线程数据库 explicit SocketConnect(QWidget *parent = 0); ~SocketConnect();private slots: void pB_lj_clicked(); // 连接按钮 void pB_dk_clicked(); // 断开连接按钮 void linkState_accept(QVector&lt;QString&gt;); // 用于在窗口显示连接状态 void data_accept(QVector&lt;QString&gt;); // 接收数据，检查后录入数据库private: QSqlDatabase *dbconn; WebserviceThread *WebT; QVector&lt;QString&gt; v_linkstate; Ui::SocketConnect *ui;&#125;;#endif // SOCKETCONNECT_H socketconnect.cpp:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126#include "socketconnect.h"#include "ui_socketconnect.h"#include "scrollwidget.h"SocketConnect::SocketConnect(QWidget *parent) : QWidget(parent), ui(new Ui::SocketConnect)&#123; ui-&gt;setupUi(this); ui-&gt;tabWidget-&gt;setTabText(1, QStringLiteral("法兰盘部件")); ui-&gt;tabWidget-&gt;setCurrentIndex(0); ui-&gt;lineEdit-&gt;setText("127.0.0.1"); // 暂时无用 ui-&gt;lineEdit_2-&gt;setText("8080"); ui-&gt;lineEdit_3-&gt;setText("helloworld"); ui-&gt;lineEdit_4-&gt;setText("helloworld"); ui-&gt;lineEdit_4-&gt;setEchoMode(QLineEdit::Password); ui-&gt;tableWidget_fla-&gt;setEditTriggers(QAbstractItemView::NoEditTriggers); // 表格不可编辑 ui-&gt;tableWidget_fla-&gt;setSelectionBehavior(QAbstractItemView::SelectRows); ui-&gt;tableWidget_fla-&gt;setAlternatingRowColors(true); ui-&gt;tableWidget_fla-&gt;setStyleSheet("QTableView&#123;alternate-background-color: rgb(183, 242, 238);&#125;"); // 设置隔行换色 connect(ui-&gt;pushButton_lj,SIGNAL(clicked(bool)),this,SLOT(pB_lj_clicked())); connect(ui-&gt;pushButton_dk,SIGNAL(clicked(bool)),this,SLOT(pB_dk_clicked()));&#125;SocketConnect::~SocketConnect()&#123; delete ui;&#125;void SocketConnect::setDbconn(QSqlDatabase *db)&#123; this-&gt;dbconn=db;&#125;void SocketConnect::pB_lj_clicked()&#123; if(ui-&gt;lineEdit_3-&gt;text()=="helloworld"&amp;&amp;ui-&gt;lineEdit_4-&gt;text()=="helloworld")&#123; WebT = new WebserviceThread(this); int port = ui-&gt;lineEdit_2-&gt;text().toInt(); WebT-&gt;setParameters(port); connect(WebT,SIGNAL(linkState_send(QVector&lt;QString&gt;)),this,SLOT(linkState_accept(QVector&lt;QString&gt;))); connect(ui-&gt;pushButton_dk,SIGNAL(clicked(bool)),WebT,SLOT(stopclick_accept())); connect(WebT,SIGNAL(data_send(QVector&lt;QString&gt;)),this,SLOT(data_accept(QVector&lt;QString&gt;))); WebT-&gt;start(); // 进入线程 &#125; else&#123; QMessageBox::critical(NULL, QString::fromLocal8Bit("警告"), QStringLiteral("账号或密码错误，无法连接！"), QMessageBox::Yes); &#125;&#125;void SocketConnect::linkState_accept(QVector&lt;QString&gt; link_state)&#123; ScrollWidget *s_linkstate = new ScrollWidget; // 自己定义的QWidget的子类，用于增加、更新、清空QList&lt;QWidget*&gt; QString linkstate; for(int i=0;i&lt;link_state.size();i++)&#123; linkstate+=link_state[i]; &#125; v_linkstate.append(linkstate); // 存储线程文件传过来的连接状态 for(int i=0;i&lt;v_linkstate.size();i++)&#123; QLabel *label_linkstate = new QLabel(v_linkstate[i]); s_linkstate-&gt;addWidget(label_linkstate); &#125; s_linkstate-&gt;updateWidget(); ui-&gt;scrollArea-&gt;setWidget(s_linkstate); // 更新scrollarea&#125;void SocketConnect::data_accept(QVector&lt;QString&gt; content)&#123; dbconn-&gt;open(); QString dataClass = content[0]; // 第一个数据存储了数据类型信息 content.erase(content.begin()); //检查编号数据是否重复或为空 dbconn-&gt;open(); if(content[0].isEmpty())&#123; QMessageBox::critical(NULL, QString::fromLocal8Bit("警告"), QStringLiteral("远程传输数据的编号为空，请检查并重新录入！"), QMessageBox::Yes); return; &#125; QSqlQueryModel *model_sql = new QSqlQueryModel; model_sql-&gt;setQuery(QString("SELECT * FROM wbq.%1").arg(dataClass)); for(int k=0 ;k&lt;model_sql-&gt;rowCount(); k++)&#123; QModelIndex index = model_sql-&gt;index(k,0); if(content[0] == model_sql-&gt;data(index).toString())&#123; QMessageBox::critical(NULL, QString::fromLocal8Bit("警告"), QStringLiteral("远程传输数据的编号已存在于数据库中，请检查并重新录入！"), QMessageBox::Yes); return; &#125; &#125; //结束检查 if(dataClass=="flange")&#123; ui-&gt;tabWidget-&gt;setCurrentIndex(1); //数据写入MySQL数据库 QSqlQueryModel *model = new QSqlQueryModel; model-&gt;setQuery(QStringLiteral("INSERT INTO wbq.coordinator SET 编号=%1, ......").arg(content[0])......; // 输入数据 dbconn-&gt;close(); delete model; //数据显示到表格中 int row = ui-&gt;tableWidget_fla-&gt;rowCount()+1; ui-&gt;tableWidget_fla-&gt;setRowCount(row); for(int i=0;i&lt;content.size();i++)&#123; ui-&gt;tableWidget_fla-&gt;setItem(row-1,i,new QTableWidgetItem); ui-&gt;tableWidget_fla-&gt;item(row-1,i)-&gt;setText(content[i]); &#125; &#125; else&#123; QMessageBox::critical(NULL, QString::fromLocal8Bit("警告"), QStringLiteral("信息格式有误或信息错误！"), QMessageBox::Yes); &#125;&#125;void SocketConnect::pB_dk_clicked()&#123; ui-&gt;scrollArea-&gt;takeWidget(); QVector&lt;QString&gt; tmp; v_linkstate.swap(tmp); ui-&gt;tableWidget_fla-&gt;setRowCount(0);&#125; 多线程头文件webservice_thread.h:123456789101112131415161718192021222324252627282930313233343536373839#ifndef WEBSERVICE_THREAD#define WEBSERVICE_THREAD#include&lt;QtSql/QSql&gt;#include&lt;QtSql/qsqlquerymodel.h&gt;#include&lt;QtSql/QSqlQuery&gt;#include&lt;QtSql/qsqldatabase.h&gt;#include&lt;QSqlError&gt;#include&lt;QStandardItem&gt;#include &lt;QThread&gt;#include &lt;QDebug&gt;#include &lt;QVector&gt;#include &lt;QMetaType&gt;#include &lt;QWaitCondition&gt;class WebserviceThread: public QThread&#123; Q_OBJECTpublic: WebserviceThread(QObject *parent=0); ~WebserviceThread(); void run(); void setParameters(int);signals: void linkState_send(QVector&lt;QString&gt;); // 向主线程发送连接状态 void data_send(QVector&lt;QString&gt;); // 向主线程发送从客户端接收的数据private slots: void stopclick_accept(); // 改变runstateprivate: QVector&lt;QString&gt; readXML(QString); int runstate; // 用于终止循环 int nPort;&#125;;#endif // WEBSERVICE_THREAD 多线程文件webservice_thread.cpp：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110#include "webservice_thread.h"#include &lt;sstream&gt;//gsoap文件#include"gservice.nsmap"#include"soapH.h"#include"soapStub.h"#include"stdsoap2.h"#include"stdsoap2.cpp"#include"soapC.cpp"#include"soapServer.cpp"QString Msg; // 存储客户端发送过来的数据WebserviceThread::WebserviceThread(QObject *parent):QThread(parent)&#123; qRegisterMetaType&lt;QVector&lt;QString&gt;&gt;("QVector&lt;QString&gt;"); runstate=0; //置1时停止网络循环&#125;WebserviceThread::~WebserviceThread()&#123;&#125;void WebserviceThread::setParameters(int port)&#123; nPort=port;&#125;int http_get_wbq(soap *);void WebserviceThread::run()&#123; struct soap wbq_soap; soap_init(&amp;wbq_soap); wbq_soap.fget = http_get_wbq; // 网上有人说如果要传输的数据量大的话应该用http post int nMaster = (int)soap_bind(&amp;wbq_soap,NULL,nPort,100); // 端口绑定 if(nMaster&lt;0) soap_print_fault(&amp;wbq_soap,stderr); else&#123; QVector&lt;QString&gt; link_state_1; link_state_1.append(QString("Socket connection successful: master socket = ")); link_state_1.append(QString::number(nMaster, 10)); emit linkState_send(link_state_1); // 发射初始连接后的状态信息 for(int i=0;;i++)&#123; int nSlave = (int)soap_accept(&amp;wbq_soap); // 端口监听，获取客户端连接信息 if(nSlave&lt;0)&#123; soap_print_fault(&amp;wbq_soap,stderr); break; &#125; QVector&lt;QString&gt; link_state_2; link_state_2.append(QString("Times ")); link_state_2.append(QString::number(i, 10)); link_state_2.append(QString(". Accepted connection from ")); link_state_2.append(QString::number(int((wbq_soap.ip&gt;&gt;24)&amp;0xFF), 10)); link_state_2.append(QString(".")); link_state_2.append(QString::number(int((wbq_soap.ip&gt;&gt;16)&amp;0xFF), 10)); link_state_2.append(QString(".")); link_state_2.append(QString::number(int((wbq_soap.ip&gt;&gt;8)&amp;0xFF), 10)); link_state_2.append(QString(".")); link_state_2.append(QString::number(int((wbq_soap.ip)&amp;0xFF), 10)); link_state_2.append(QString(": slave socket = ")); link_state_2.append(QString::number(nSlave, 10)); if(!runstate) emit linkState_send(link_state_2); // 发射客户端连接信息 if(runstate)//点击断开连接后的下一次循环可以ping通，但无法调用服务端的sendMsg方法，即数据无法传送，不会造成数据丢失。 break; if(soap_serve(&amp;wbq_soap)!=SOAP_OK) soap_print_fault(&amp;wbq_soap,stderr); soap_destroy(&amp;wbq_soap); soap_end(&amp;wbq_soap); QVector&lt;QString&gt; data = readXML(Msg); // 解析数据 emit data_send(data); // 向主线程传递解析后的数据 Msg=""; &#125; &#125; soap_done(&amp;wbq_soap);&#125;void WebserviceThread::stopclick_accept()&#123; runstate = 1;&#125;/*此功能是按自己格式解析的*/QVector&lt;QString&gt; WebserviceThread::readXML(QString Msg)&#123; QVector&lt;QString&gt; data; QStringList msglist = Msg.split(","); for(int i=0;i&lt;msglist.size();i++)&#123; data.append(msglist[i]); &#125; return data;&#125;int ns__sendMsg(struct soap *soap, char* smsg, nullResponse* result)&#123; Msg = QString(smsg); return SOAP_OK;&#125;/*用于在网页页面正常显示信息（百度得到的解决方案）*/int http_get_wbq(struct soap *soap)&#123; soap_response(soap, SOAP_HTML); // HTTP response header with text/html soap_send(soap, "&lt;HTML&gt;My Web server is operational.&lt;/HTML&gt;"); soap_end_send(soap); return SOAP_OK;&#125; 存在问题1、gSOAP中有对数据序列化与反序列化的功能，不应按自己的格式来传送数据；2、断开连接按功能在问题，不能及时断开连接。点击“断开连接”按钮后，客户端需要再试图与服务端通信一次，服务端才能真正跳出循环，目前只能做到最后一次通信客户端报错，数据无法传送，不会造成数据丢失。 Reference:[1] Qt中多线程的使用：https://blog.csdn.net/mao19931004/article/details/53131872[2] Qt使用多线程的一些心得——1.继承QThread的多线程使用方法：https://blog.csdn.net/czyt1988/article/details/64441443[3] WebService学习总结(一)——WebService的相关概念：https://www.cnblogs.com/xdp-gacl/p/4048937.html[4] gsoap使用总结：https://blog.csdn.net/byxdaz/article/details/51679117]]></content>
      <categories>
        <category>Qt</category>
      </categories>
      <tags>
        <tag>Qt</tag>
        <tag>Multithreading</tag>
        <tag>webservice</tag>
        <tag>xml</tag>
        <tag>gsoap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Qt+Python混合编程]]></title>
    <url>%2F2018%2F08%2F13%2FQt%2BPython%E6%B7%B7%E5%90%88%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[项目使用Qt搭建了一个数据库软件，这个软件还需要有一些数据分析、特征重要度计算、性能预测等功能，而python的机器学习第三方库比较成熟，使用起来也比较便捷，因此这里需要用到Qt(c++)+python混合编程，在此记录一下相关方法与问题，以方便自己与他人。 本项目使用的是QtCreator(Qt5.5.0)+VisualStudio2013+python3.6.5搭建。其他版本只要版本是正确对应的，都大同小异。 准备工作假设你已经正确安装了Qt和python，由于Qt中的slots关键字与python重复，这里我们需要修改一下文件../Anaconda/include/object.h(注意先将原文件备份)：原文件(448行)：1234567typedef struct&#123; const char* name; int basicsize; int itemsize; unsigned int flags; PyType_Slot *slots; /* terminated by slot==0. */&#125; PyType_Spec; 修改为：123456789typedef struct&#123; const char* name; int basicsize; int itemsize; unsigned int flags; #undef slots // 这里取消slots宏定义 PyType_Slot *slots;/* terminated by slot==0. */ #define slots Q_SLOTS // 这里恢复slots宏定义与QT中QObjectDefs.h中一致&#125; PyType_Spec; 完成上述工作后我们需要在.pro文件中加入python的路径信息(我的python路径是Y:/Anaconda)：123INCLUDEPATH += -I Y:/Anaconda/includeLIBS += -LY:/Anaconda/libs -lpython36 将python3.dll，python36.dll，pythoncom36.dll，pywintypes36.dll放到.exe目录下。 Qt调用python脚本python文件创建一个python脚本放在release项目目录下，这里我们新建了一个kde.py,其中包含无返回值函数plotKDE(x, column, kernel, algorithm, breadth_first, bw, leaf_size, atol, rtol, title)用于绘制核KDE曲线与直方图和有返回值函数loadData()用于读取本地.csv文件，图像绘制效果如下所示： kde.py部分代码如下(为方便表达，后续步骤中我们将plotKDE函数简写为plotKDE(x, column， kernel))：1234567891011121314151617181920212223242526272829303132333435363738import csvimport osimport matplotlib as mplfrom matplotlib import pyplot as pltimport numpy as npfrom sklearn.neighbors import KernelDensitympl.use('TkAgg')mpl.rcParams['font.sans-serif'] = ['SimHei']mpl.rcParams['axes.unicode_minus'] = FalseBASE_DIR = os.path.dirname(__file__)file_path = os.path.join(BASE_DIR, 'train.csv')def plotKDE(x, column, kernel='gaussian', algorithm='auto', breadth_first=1, bw=30, leaf_size=40, atol=0, rtol=1E-8, title): # kde x_plot = np.linspace(min(x), max(x), 1000).reshape(-1, 1) x = np.mat(x).reshape(-1, 1) fig, ax = plt.subplots() kde = KernelDensity(bandwidth=bw, algorithm=algorithm, kernel=kernel, atol=atol, rtol=rtol, breadth_first=breadth_first, leaf_size=leaf_size).fit(x) log_dens = kde.score_samples(x_plot) ax.hist(x, density=True, color='lightblue') ax.plot(x_plot[:, 0], np.exp(log_dens)) plt.title(title[column]) plt.show()def loadData(): x = [] with open(file_path, 'rt') as csvfile: reader = csv.reader(csvfile) for line in reader: tmp = list(map(float, line[4:])) x.append(tmp) return x Qvector转pyObject类型此处新建了一个类用于将Qt中存储的数据的QVector&lt;double&gt;类型等转换为用于python脚本的QObject类型。QVector&lt;QVector&lt;double&gt;&gt;的转换方法可以此类推。12345678910PyObject *Utility::UtilityFunction::convertLabelData(QVector&lt;double&gt; *labels)&#123; int labelSize = labels-&gt;size(); PyObject *pArgs = PyList_New(labelSize); for (int i = 0; i &lt; labelSize; ++i) &#123; PyList_SetItem(pArgs, i, Py_BuildValue("d", (*labels)[i])); &#125; return pArgs;&#125; Qt调用python脚本在Qt项目中调用kde.py的plotKDE函数显示图像(有输入，无返回值)：12345678910111213141516171819202122232425262728293031323334353637383940414243444546// 初始化Py_Initialize();if (!Py_IsInitialized()) &#123; printf("inititalize failed"); qDebug() &lt;&lt; "inititalize failed"; return ;&#125;else &#123; qDebug() &lt;&lt; "inititalize success";&#125;// 加载模块，即loadtraindata.pyPyObject *pModule = PyImport_ImportModule("kde");if (!pModule) &#123; PyErr_Print(); qDebug() &lt;&lt; "not loaded!"; return ;&#125;else &#123; qDebug() &lt;&lt; "load module success";&#125;// QVector&lt;double&gt; pKDE中存放了选中列的所有数据PyObject *pKDEdata = Utility::UtilityFunction::convertLabelData(&amp;pKDE); // 类型转换PyObject *pArg = PyTuple_New(3);PyTuple_SetItem(pArg, 0, pKDEdata);// int column表示选中的列的索引PyTuple_SetItem(pArg, 1, Py_BuildValue("i", column));// Qstring kernel表示核类型PyTuple_SetItem(pArg, 2, Py_BuildValue("s", kernel.toStdString().c_str()));// 加载函数loadData()PyObject *pFunc = PyObject_GetAttrString(pModule, "plotKDE");if (!pFunc) &#123; printf("get func failed!");&#125;else &#123; qDebug() &lt;&lt; "get func success";&#125;PyObject_CallObject(pFunc, pArg);Py_DECREF(pModule);Py_DECREF(pFunc);Py_Finalize(); 在Qt项目中调用kde.py的loadData函数读取本地数据(无输入，有返回值)：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960Py_Initialize();QVector&lt;QVector&lt;double&gt; &gt; *trainData; // 存储python脚本读入的数据if (!Py_IsInitialized()) &#123; printf("inititalize failed"); qDebug() &lt;&lt; "inititalize failed"; return ;&#125;else &#123; qDebug() &lt;&lt; "inititalize success";&#125;// 添加当前路径(读文件的时候才需要)PyRun_SimpleString("import sys");PyRun_SimpleString("sys.path.append('./')");// 加载模块，即loadtraindata.pyPyObject *pModule = PyImport_ImportModule("kde");if (!pModule) &#123; PyErr_Print(); qDebug() &lt;&lt; "not loaded!"; return ;&#125;else &#123; qDebug() &lt;&lt; "load module success";&#125;// 加载函数loadData()PyObject *pLoadFunc = PyObject_GetAttrString(pModule, "loadData");if (!pLoadFunc) &#123; printf("get func failed!");&#125;else &#123; qDebug() &lt;&lt; "get func success";&#125;PyObject *retObjectX = PyObject_CallObject(pLoadFunc, NULL); // 获得python脚本返回数据if (retObjectX == NULL) &#123; qDebug() &lt;&lt; "no return value"; return ;&#125;/*将retObjectX导入trainData中(二维数据)*/int row = PyList_Size(retObjectX);for (int i = 0; i &lt; row; ++i) &#123; PyObject *lineObject = PyList_GetItem(retObjectX, i); int col = PyList_Size(lineObject); QVector&lt;double&gt; tmpVect; for (int j = 0; j &lt; col; ++j) &#123; PyObject *singleItem = PyList_GetItem(lineObject, j); double item = PyFloat_AsDouble(singleItem); tmpVect.push_back(item); &#125; trainData-&gt;push_back(tmpVect);&#125;Py_Finalize(); 注意事项这里列写一下软件搭建过程中遇到的问题，以供参考。 重装python的话别忘了修改.pro文件中的python路径； importError:dll not load：常见的matplotlib,numpy等DLL加载错误，通常是由python与对应的第三方包的版本不一致导致的。将anaconda文件下的python.dll和python3.dll文件拷贝到qt可执行文件exe同级目录下并覆盖。 多次调用Py_Initialize()和Py_Finalize()可能会出现异常：最好在main.cpp里就输入Py_Initialize()，程序最后再Py_Finalize()。 Reference:[1] QT与Python混合编程经验记录：http://www.cnblogs.com/jiaping/p/6321859.html[2] C++调用python浅析：https://blog.csdn.net/magictong/article/details/8947892]]></content>
      <categories>
        <category>Qt</category>
      </categories>
      <tags>
        <tag>Qt</tag>
        <tag>python</tag>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Qt+MySQL编程]]></title>
    <url>%2F2018%2F08%2F12%2FQt%2BMySQL%E7%BC%96%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[项目需要开发一个数据库软件，并且整个软件都是使用Qt搭建的，数据库选用的是MySQL，因此需要使用Qt调用MySQL，在此记录一下相关方法与问题，以方便自己与他人。 本项目使用的是QtCreator(Qt5.5.0)+VisualStudio2013+MySQL5.7.17.0搭建。其他版本只要版本是正确对应的，都大同小异。 准备工作假设你已经正确安装了Qt和MySQL，并且已经将文件../MySQL/MySQL Server 5.7/lib/libmysql.dll复制到文件夹../Qt5.5.0/5.5/msvc2013_64/bin中，将文件../MySQL/MySQL Server 5.7/lib/libmysql.lib复制到文件夹../Qt5.5.0/5.5/msvc2013_64/lib中。之前遇到过MySQL安装过程中卡在MySQL Serve加载处，网络上的各种方法都没用，最后发现可能是使用了XX-Net等网络代理工具的问题，解决方法是关闭网络防火墙。 Qt链接MySQL数据库首先在xxx.pro工程文件中添加：1QT += sql 在相应文件中引入相关头文件：1234#include &lt;QSql&gt;#include &lt;QSqlQueryModel&gt;#include &lt;QSqlDatabase&gt;#include &lt;QSqlQuery&gt; 在mainwindow.h文件的构造函数中添加：12345QString hostName;QString dbName;QString userName;QString password;QSqlDatabase dbconn; 在mainwindow.cpp文件的构造函数中添加：1234567891011121314151617hostName = "localhost"; // 主机名dbName = "wbq"; // 数据库名称userName = "root"; // 用户名password = "helloworld"; // 密码dbconn = QSqlDatabase::addDatabase("QMYSQL");dbconn.setHostName(hostName);dbconn.setDatabaseName(dbName);dbconn.setUserName(userName);dbconn.setPassword(password);qDebug("database open status: %d\n", dbconn.open());QSqlError error = dbconn.lastError();qDebug() &lt;&lt; error.text();dbconn.close(); 如果数据库能够成功打开则调试窗口会出现以下信息：123database open status: 1&quot; &quot; 主界面创建了数据库dbconn后，其他界面若需调用数据库只用定义一个子类成员函数：1234void subwindow::setDbconn(QSqlDatabase *dbconn)&#123; this-&gt;dbconn = dbconn;&#125; 然后在mainwindow.cpp文件对应处调用该函数。 Qt的MySQL数据库操作读取MySQL数据库中某表格的字段名通过以下代码可以将MySQL中某表格中的字段名读取到一个QSqlQueryModel中，读取model中的数据可以获取到字段名。1234QSqlQueryModel *model_name = new QSqlQueryModel;model_name-&gt;setQuery(QString("select COLUMN_NAME from information_schema.COLUMNS where table_name = 'your_table_name' and table_schema = 'your_db_name'"));QModelIndex index_name = model_name-&gt;index(1,0); // model为n行1列qDebug()&lt;&lt;model_name-&gt;data(index_name).toString(); 读取MySQL数据并输入到TableView中MySQL数据库中数据可以看成一个model。假设要读取wbq数据库中的cursheet表，读取方式如下：12345dbconn-&gt;open();QSqlQueryModel *model = new QSqlQueryModel;model-&gt;setQuery(QString("SELECT * FROM %1").arg("wbq.cursheet"));ui-&gt;tableView-&gt;setModel(model);dbconn-&gt;close(); 读取MySQL多个表并根据主键值匹配融合成一个表通常在读入数据后可能需要对多附表进行匹配操作，此时需要读取表中具体元素的数据，方法如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/*定义一个用于存储匹配结果的model*/QStandardItemModel model_merge = new QStandardItemModel(ui-&gt;tableView)/*从wbq数据库中读取两个表进行匹配*/dbconn-&gt;open();QSqlQueryModel *model_1 = new QSqlQueryModel;model_1-&gt;setQuery(QString("SELECT * FROM wbq.sheet1"));QSqlQueryModel *model_2 = new QSqlQueryModel;model_2-&gt;setQuery(QString("SELECT * FROM wbq.sheet2"));/*将model_1中数据输入到model_merge中*/for(int i=0;i&lt;model_1-&gt;rowCount();i++)&#123; for(int j=0;j&lt;model_1-&gt;columnCount();j++)&#123; QModelIndex index = model_1-&gt;index(i,j); model_merge-&gt;setItem(i,j,new QStandardItem(model_1-&gt;data(index).toString())); &#125;&#125;/*将model_2中的数据与model_merge进行匹配(算法未优化，还望各位多包涵)*/QVector&lt;int&gt; nullRow_2; // 用于记录空值for(int i=0;i&lt;model_merge-&gt;rowCount();i++)&#123; QModelIndex index_m = model_merge-&gt;index(i,1); for(int j=0;j&lt;model_2-&gt;rowCount();j++)&#123; QModelIndex index_2 = model_2-&gt;index(j,0); // 若两组数据键值相等，则将model_2数据扩展到model_merge已有列之后 if(model_merge-&gt;data(index_m).toString()==model_2-&gt;data(index_2).toString())&#123; for(int k=1;k&lt;model_2-&gt;columnCount();k++)&#123; QModelIndex index_m2 = model_2-&gt;index(j,k); model_merge-&gt;setItem(i,k+22,new QStandardItem(model_2-&gt;data(index_m2).toString())); &#125; break; &#125; // 如果遍历完依然没有匹配上则存入nullRow_2 if(j==(model_2-&gt;rowCount()-1))&#123; nullRow_2.append(i); &#125; &#125;&#125;// 删除nullRow_2中存放的无法匹配的数据for(int i=nullRow_2.size();i&gt;0;i--)&#123; model_merge-&gt;removeRow(nullRow_2[i-1]);&#125; 增加操作假设要向wbq数据库中的cursheet表增加数据,QVector&lt;QString&gt; validStringVect为数据名称，QVector&lt;QLineEdit*&gt; validLineEditVect为数据值：123456789101112131415161718192021222324252627/*创建语句头*/QString sqlStr = "";sqlStr += QString("INSERT INTO wbq.%1 SET").arg(curSheet);dbconn-&gt;open();/*为每一组数据在sqlstr中扩充相应的语句*/for (int i = 0; i &lt; validStringVect.size(); ++i) &#123; sqlStr += QString(" `%1`='%2'").arg(validStringVect.at(i)).arg(validLineEditVect.at(i)-&gt;text()); if (i &lt; validStringVect.size()-1) &#123; sqlStr += ","; &#125;&#125;// 中文的话需要注意sqlstr的编码问题/*将语句sqlstr发送到MySQL，进行相应的操作*/QSqlQueryModel *model = new QSqlQueryModel;model-&gt;setQuery(sqlStr);model-&gt;setQuery(QString("SELECT * FROM %1").arg("wbq.cursheet")); // 刷新表格dbconn-&gt;close(); 删除操作删除操作通过寻找主键完成对某一组数据的删除工作，具体实现如下所示：12345678910111213141516171819202122232425262728293031/*获取表格中的选中行索引（可为多行）*/std::set&lt;int&gt; rowSet;QModelIndexList indexList = ui-&gt;tableView-&gt;getSelectedIndexs();int indexNum = indexList.size();for (int i = 0; i &lt; indexNum; ++i) &#123; rowSet.insert(indexList.at(i).row());&#125;/*根据主键值遍历删除选中行*/for (iter = rowSet.begin(); iter != rowSet.end(); ++iter) &#123; QModelIndex indexToDel = model-&gt;index((*iter), 0); QString tmpSql; tmpSql = QString(QStringLiteral("DELETE FROM wbq.%1 WHERE index='%2'")).arg(curSheet).arg(indexToDel.data().toString()); dbconn-&gt;open(); QSqlQueryModel *model = new QSqlQueryModel; model-&gt;setQuery(tmpSql); dbconn-&gt;close();&#125;/*刷新表格*/dbconn-&gt;open();QSqlQueryModel *model = new QSqlQueryModel;model-&gt;setQuery(QString("SELECT * FROM %1").arg("wbq.cursheet"));ui-&gt;tableView-&gt;setModel(model);dbconn-&gt;close(); 编辑操作通过对TableView中某item数据修改完成对MySQL对应元素数据的修改，具体方法如下：12345678910111213141516171819QString column_en[8] = &#123;......&#125; // 存储表格中的所有可编辑列列名QModelIndex curIndex = ui-&gt;tableView-&gt;currentIndex(); // 获取当前选中的item的indexQAbstractItemModel *model = ui-&gt;tableView-&gt;model();QModelIndex primaryIndex = model-&gt;index(curIndex.row(), 0); // 获取选中行第一列的index(主键值)QString primaryKey = primaryIndex.data().toString(); // 获取选中行的主键值QString editColumn = pColumn[curIndex.column()]; // 获取选中列列名QString editStr = tmpLineEdit-&gt;text(); // item修改后的值QString updateStr;updateStr = QString(QStringLiteral("UPDATE wbq.%1 SET %2='%3' WHERE 主键值='%4'")).arg(this-&gt;curSheet).arg(editColumn).arg(editStr).arg(primaryKey);dbconn-&gt;open();QSqlQueryModel *model = new QSqlQueryModel;model-&gt;setQuery(updateStr);model-&gt;setQuery(QString("SELECT * FROM %1").arg("wbq.cursheet")); // 刷新表格ui-&gt;tableView-&gt;setModel(model);dbconn-&gt;close(); 查询操作软件中输入某列或某几列数据的上下限，完成查询功能。具体方法如下：123456789101112131415161718192021222324252627QString sqlStr = "";sqlStr += QString("SELECT * FROM wbq.%1 WHERE ").arg(curSheet);// 遍历各列数据的上下限bool first = true;for (int i = 0; i &lt; searchField.size(); ++i) &#123; if (!this-&gt;startLineEdit.at(i)-&gt;text().isEmpty()) &#123; if (!first) sqlStr += QString(" AND "); sqlStr += QString(" `%1` &gt; %2 ").arg(searchField.at(i)).arg(startLineEdit.at(i)-&gt;text()); first = false; &#125; if (!this-&gt;endLineEdit.at(i)-&gt;text().isEmpty()) &#123; if (!first) sqlStr += QString(" AND "); sqlStr += QString(" `%1` &lt; %2 ").arg(searchField.at(i)).arg(endLineEdit.at(i)-&gt;text()); first = false; &#125;&#125;if (first) // 防止出现所有列上下限都没有设置的情况 sqlStr += QString("1=1"); dbconn-&gt;open();QSqlQueryModel *model = new QSqlQueryModel;model-&gt;setQuery(sqlStr);ui-&gt;tableView-&gt;setModel(model);dbconn-&gt;close(); 统计计算项目要求软件实现对数据统计特征的计算功能，此处也是直接调用MySQL语句进行操作。具体方法如下：1234567891011121314151617181920212223242526272829303132333435363738394041dbconn-&gt;open();QVector&lt;QString&gt; calStr = &#123;"AVG", "STD", "MAX", "MIN"&#125;; // 四种统计属性QSqlQueryModel *queryModel = new QSqlQueryModel; // 获取各列统计信息的modelQVector&lt;QVector&lt;QString&gt;&gt; gVect; // 存储各列统计信息QVector&lt;QString&gt; fieldStr; // 需要统计的列名(假设已赋值)/*获取queryModel*/for (int i = 0; i &lt; calStr.size(); ++i) &#123; QString queryStr = QString("SELECT "); for (int j = 0; j &lt; fieldStr.size(); ++j) &#123; queryStr.append(QString("%1(CAST(`%2` AS DECIMAL(8, 2)))").arg(calStr[i]).arg(fieldStr[j])); // 8代表数值长度，2代表小数位数 if (j &lt; fieldStr.size()-1) queryStr.append(QString(",")); &#125; queryStr.append(QString(" FROM wbq.%1").arg(this-&gt;curSheet)); queryModel-&gt;setQuery(queryStr); /* queryModel读取到gVect中 */ int colCount = queryModel-&gt;columnCount(); QVector&lt;QString&gt; rowVect; for (int j = 0; j &lt; colCount; ++j) &#123; rowVect.push_back(QString("%1").arg(queryModel-&gt;index(0, j).data().toFloat())); &#125; gVect.push_back(rowVect);&#125;dbconn-&gt;close();/*显示各列统计信息*/QAbstractTableModel *model = new QAbstractTableModel；model-&gt;setDataVect(gVect);QVector&lt;QString&gt; calStr_cn = &#123;QStringLiteral("平均数"), QStringLiteral("方差"), QStringLiteral("最大值"), QStringLiteral("最小值")&#125;;model-&gt;setHeaderVect(fieldStr, calStr_cn);ui-&gt;tableView-&gt;setModel(model)； // 刷新表格 Qt+MySQL发布此步同样适用于一般的Qt软件发布。1). 单独将.exe执行程序放到一个空文件夹；2). 在开始菜单打开Qt5.5 64-bit for Desktop (msvc 2013)并cd命令到此文件夹；3). 运行命令windeployqt 文件名.exe，将生成的所有文件复制到release文件夹中；4). 将libmysql.dll复制到release文件夹中。 使用该软件的主机需要安装对应版本的MySQL，并将已存在的数据库导入。 注意事项这里列写一下软件搭建过程中遇到的问题，以供参考。 重装Qt后数据库无法连上：将release文件夹中Qt的.dll用新装的Qt替代，哪怕Qt版本一致。 出现错误cant connect mysql server on 127.0.0.1(10060)，mysql workbench无法连接，但MySQL Serve显示正在运行：关闭网络防火墙。 QT移植无法启动This application failed to start because it could not find or load the Qt platform plugin：1). 将../Qt5.5.0/5.5/msvc2013_64/bin中的所有.dll复制到.exe目录下，尽管右下可能用不到；2). 将文件夹../Qt5.5.0/5.5/msvc2013_64/plugins/platforms直接复制到.exe目录下。 在Qt5.5 64-bit for Desktop (msvc 2013)中输入windeployqt 文件名.exe时报错Warning: Cannot find Visual Studio installation directory, VCINSTALLDIR is not set.：直接用 “VS2013 开发人员命令提示” 命令行去执行刚才的windeployqt 文件名.exe，会将 “vcredist_x64.exe”（vc x64 运行最少环境）程序放入当前目录。 Reference:[1] 在QT中使用MySQL数据库：https://blog.csdn.net/yunzhifeiti/article/details/72709140[2] QT移植无法启动 This application failed to start because it could not find or load the Qt platform plugin：https://blog.csdn.net/jzwong/article/details/71479691]]></content>
      <categories>
        <category>Qt</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
        <tag>C++</tag>
        <tag>Qt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo+GitHub搭建私人博客]]></title>
    <url>%2F2018%2F08%2F11%2FHexo%2BGitHub%E6%90%AD%E5%BB%BA%E7%A7%81%E4%BA%BA%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[使用GitHub作为服务器搭建自己的私人博客相对来说成本更低且更容易实现，缺点是国内的搜索引擎无法检索到你的网页信息。GithUb提供了一个Github Pages的服务，可以为托管在Github上的项目提供静态页面。从零开始，博客具体搭建步骤如下： 安装Git这一步可以参考廖雪峰的Git教程：https://www.liaoxuefeng.com/wiki/0013739516305929606dd18361248578c67b8067c8c017b000/00137396287703354d8c6c01c904c7d9ff056ae23da865a000一路默认安装即可。安装完成后，需要进一步进行设置，在命令行输入：12$ git config --global user.name &quot;Your Name&quot;$ git config --global user.email &quot;email@example.com&quot; 其中第一句的“名称”和第二句的“邮箱”替换成你自己的名字与E-mail地址，此步相当于注册你这台机器的信息。为了实现在Github中对Git仓库进行托管服务，我们需要先注册一个Github账号，然后创建SSH Key。打开Shell(Windows下打开Git Bash)，输入：1$ ssh-keygen -t rsa -C &quot;youremail@example.com&quot; 同样将邮箱地址换成你自己的邮箱地址。一路确认，会在用户主目录下创建一个.ssh的文件夹，里面有id_rsa和id_rsa.pub这两个文件，这两个就是SSH Key的秘钥对，id_rsa是私钥，不能泄露出去，id_rsa.pub是公钥，可以放心地告诉任何人。登录Github，打开“Account settings”，“SSH Keys”页面，然后，点“Add SSH Key”，填上任意Title，在Key文本框里粘贴id_rsa.pub文件的内容：点“Add Key”，你就应该看到已经添加的Key： 安装Node.js与Hexo点击链接下载Node.js安装包：https://nodejs.org/dist/v8.11.3/node-v8.11.3-x64.msi一路默认安装即可，完成后打开控制台，如果安装成功会显示如下信息： 安装Hexo。首先在本地创建一个用于写blog的文件夹，并使用cd命令进入该文件夹目录。在命令行输入$ npm install hexo -g安装Hexo。输入hexo -v检查Hexo是否安装成功：输入hexo init初始化该文件夹(漫长的等待…)，看到最后出现”Start blogging with Hexo!”即表示安装成功。接着输入npm install以安装所需的组件。 连接Hexo与Github(仅限于第一次搭建博客)在当前目录下找到并打开文件_config.yml，修改repository值(在末尾)：1234deploy: type: git repository: git@github.com:KunBB/KunBB.github.io.git branch: master repository值是你在Github项目里的ssh，如下图所示：注意blog中的所有配置文件名称与值之间都要有空格，否则不会生效。如type:git错误，type: git正确。 Hexo中使用Latex编写公式安装Kramed由于很多博客中会涉及到一些公式，而markdown本身的公式编写较为麻烦，作为一名科研工作者，Latex格式一定是相当熟悉的东西，因此我们需要通过安装第三方库来配置Hexo使用Latex格式书写公式。 Hexo默认的渲染引擎是marked，但是marked不支持mathjax，所以需要更换Hexo的markdown渲染引擎为hexo-renderer-kramed引擎，后者支持mathjax公式输出。12$ npm uninstall hexo-renderer-marked --save$ npm install hexo-renderer-kramed --save 更改文件配置打开文件”../node_modules/hexo-renderer-kramed/lib/renderer.js”进行修改(末尾)：123456789101112// Change inline math rulefunction formatText(text) &#123; // Fit kramed&apos;s rule: $$ + \1 + $$ return text.replace(/`\$(.*?)\$`/g, &apos;$$$$$1$$$$&apos;);&#125;修改为：// Change inline math rulefunction formatText(text) &#123; return text;&#125; 停止使用hexo-math并安装mathjax包卸载hexo-math：1$ npm uninstall hexo-math --save 安装hexo-renderer-mathjax包:1$ npm install hexo-renderer-mathjax --save 更新Mathjax配置文件打开文件”../node_modules/hexo-renderer-mathjax/mathjax.html”，将的src修改为： "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML" 即： 更改默认转义规则因为LaTeX与markdown语法有语义冲突，所以Hexo默认的转义规则会将一些字符进行转义，所以我们需要对默认的规则进行修改。打开文件”../node_modules/kramed/lib/rules/inline.js”：1.将1escape: /^\\([\\`*&#123;&#125;\[\]()#$+\-.!_&gt;])/, 更改为1escape: /^\\([`*\[\]()# +\-.!_&gt;])/, 2.将1em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/, 更改为1em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/, 开启mathjax打开文件”../Hexo/themes/next/_config.yml”，找到含有”mathjax”的字段进行如下修改：12345# MathJax Supportmathjax: enable: true per_page: true cdn: //cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML 写博客的时候需要在开头开启mathjax选项，添加以下内容：123456title: LibSVM支持向量回归详解date: 2018-01-30 10:10:00categories: &quot;SVM&quot;tags: -Machine learningmathjax: true 上传博客在Shell(Windows下打开Git Bash)中输入1$ hexo s 可在本地查看博客效果，默认端口号为4000，地址：http://localhost:4000/注意复制时不要用ctrl+c(会终止进程)。若页面一直无法跳转，可能是端口被占用，此时可以输入hexo server -p 端口号来改变端口号。在Shell(Windows下打开Git Bash)中输入1$ hexo d -g 可将本地博客推送到Github服务器，完成私人博客更新。 其他博客图片管理博客中所插入的图片需要图片链接，由于博客托管于Github服务器，所以如果博客中图片链接为国内网页的链接则可能存在图片加载缓慢甚至无法加载的现象。为解决这个问题我们可以在Github上新建一个Repo用于存放博客中所需要的图片，将图片的Github链接写入博客。 博客文件管理当电脑重装系统或需要跟换电脑时，hexo+git往往需要重新配置，博客文件也需要复制到当前主机。因此比较方便的操作就是在Github上新建一个Repo用于存放blog目录的所有文件，当博客更新时，将最近版push到github。 Reference:[1] 使用Hexo+Github一步步搭建属于自己的博客（基础）：https://www.cnblogs.com/fengxiongZz/p/7707219.html[2] hexo+github搭建个人博客(超详细教程)：https://blog.csdn.net/ainuser/article/details/77609180[3] 如何在 hexo 中支持 Mathjax？：https://blog.csdn.net/u014630987/article/details/78670258[4] 使用LaTex添加公式到Hexo博客里：https://blog.csdn.net/Aoman_Hao/article/details/81381507]]></content>
      <categories>
        <category>Blog</category>
      </categories>
      <tags>
        <tag>blog</tag>
        <tag>Hexo</tag>
        <tag>GitHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LibSVM支持向量回归详解]]></title>
    <url>%2F2018%2F01%2F30%2Flibsvm%20SVR%E9%83%A8%E5%88%86%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[LibSVM是是台湾林智仁(Chih-Jen Lin)教授2001年开发的一套支持向量机的库，可以很方便的对数据做分类或回归。由于LibSVM程序小，运用灵活，输入参数少，并且是开源的，易于扩展，因此成为目前国内应用最多的SVM的库，同时sklearn.svm也是使用的该库。 网络上对于LibSVM源码的讲解有很多，但个人感觉绝大多数讲解的不够清晰，很多都是贴个理论公式图片再粘段代码就一带而过。并且网络上基本都是对SVC的讲解，SVR部分几乎没有提及（虽然SVR只是SVC的扩展）。因此本篇博文将系统地讲解LibSVM中SVR训练与预测部分的源码（想学习SVC的同学同样适用）。 LibSVM整体流程train：1234567891011121314151617181920//根据svm_type的不同进行初始化svm_train() //根据svm_type的不同调用不同的分类回归训练函数 svm_train_one() //针对epsilon-SVR这一类型进行模型参数初始化 solve_epsilon_svr() //使用SMO算法求解对偶问题（二次优化问题） Solver::Solve() //每隔若干次迭代进行一次shrinking，对样本集进行缩减降低计算成本 Solver::do_shrinking() //若满足停止条件则进行梯度重建并跳出循环 Solver::reconstruct_gradient() //选择出当前最大违反对i,j Solver::select_working_set() //计算参数优化后的rho Solver::caculate_rho() //得到优化后的alpha和SolutionInfo对象si //得到优化后的alpha和SolutionInfo对象si //得到decision_function对象f//得到svm_model对象model predict123456789//根据svm_type的不同开辟dec_value空间svm_predict() //根据svm_type的不同调用k_function函数 svm_predict_values() //根据kernel_type的不同计算k(i,j) Kernel::k_function() //得到k(x_train[i],x_test[j]) //得到预测值y_pre[j]//得到预测值y_pre[j] svm.h文件解析svm_node12345//存储一个样本（假设为样本i）的一个特征struct svm_node&#123; int index; //样本i的特征索引值，最后一个为-1 double value; //样本i第index个特征的值，最后一个为NULL&#125;; 如：x[i]={0.23,1.2,3.5,1.5}则需使用五个svm_node来表示x[i]，具体映射如下： index 0 1 2 3 -1 value 0.23 1.2 3.5 1.5 NULL svm_problem123456//存储参加运算的所有样本数据（训练集）struct svm_problem&#123; int l; //样本总数 double *y; //样本输出值（所属类别） struct svm_node **x; //样本输入值&#125;; 下图中最右边的长条格同上表，存储了三维数据。 svm_problem中的y与类Solver中的y并不完全一样!!!对于一般SVC而言可以看出一样的，其值为-1与+1，对于多分类而言svm_problem.y[i]可以是1、2、3等，而多类计算其实是二分类的组合，因此在二分类中y[i]依然等于+1与-1.更特殊的，在SVR中，svm_problem的y[i]等于其目标值，如：11.234、56.24、5.23等，在计算时svm_problem.y[i]整合到了Solver.p[i]与Solver.p[i+svm_problem.l]中（具体的问题后续章节再详细解释），而在Solver.y[i]依然为+1和-1. svm_parameter12345678910111213141516171819202122232425//svm_type和svm_type可能取值enum &#123; C\_SVC, NU\_SVC, ONE\_CLASS, EPSILON\_SVR, NU\_SVR &#125;;/* svm_type */enum &#123; LINEAR, POLY, RBF, SIGMOID &#125;; /* kernel_type *///svm模型训练参数struct svm_parameter &#123; int svm_type; int kernel_type; int degree; /* for poly */ double gamma; /* for poly/rbf/sigmoid */ double coef0; /* for poly/sigmoid */ /* these are for training only */ double cache_size; /* in MB */ double eps; /* stopping criteria */ double C; /* for C_SVC, EPSILON_SVR and NU_SVR */ int nr_weight; /* for C_SVC */ int *weight_label; /* for C_SVC */ double* weight; /* for C_SVC */ double nu; /* for NU_SVC, ONE_CLASS, and NU_SVR */ double p; /* for EPSILON_SVR */ int shrinking; /* use the shrinking heuristics */ int probability; /* do probability estimates */ &#125;; LibSVM中的核函数如下： 各参数解释如下： Parameter Interpretation degree 2式中的d gamma 2,3,4式中的gamma coef0 2,4式中的r cache_size 单位MB，训练所需内存，LibSVM2.5默认4M eps 停止条件需满足的最大误差值(文献[2]中式3.9) C 惩罚因子，越大模型过拟合越严重 nr_weight 权重的数目,目前在实例代码中只有两个值，一个是默认0，另外一个是svm_binary_svc_probability函数中使用数值2 *weight_label 权重，元素个数由nr_weight决定. nu NU_SVC,ONE_CLASS,NU_SVR中的nu p SVR中的间隔带epsilon shrinking 指明训练过程是否使用压缩 probability 指明是否做概率估计 svm_model123456789101112131415161718192021//保存训练后的模型参数struct svm_model&#123; struct svm_parameter param; /* parameter */ int nr_class; /* number of classes, = 2 in regression/one class svm */ int l; /* total #SV */ struct svm_node **SV; /* SVs (SV[l]) */ double **sv_coef; /* coefficients for SVs in decision functions (sv_coef[k-1][l]) */ double *rho; /* constants in decision functions (rho[k*(k-1)/2]) */ double *probA; /* pariwise probability information */ double *probB; int *sv_indices; /* sv_indices[0,...,nSV-1] are values in [1,...,num_traning_data] to indicate SVs in the training set */ /* for classification only */ int *label; /* label of each class (label[k]) */ int *nSV; /* number of SVs for each class (nSV[k]) */ /* nSV[0] + nSV[1] + ... + nSV[k-1] = l */ /* XXX */ int free_sv; /* 1 if svm_model is created by svm_load_model*/ /* 0 if svm_model is created by svm_train */&#125;; 各参数解释如下： Parameter Interpretation param 训练参数 nr_class 类别数 l 支持向量数 **SV 作为支持向量的样本集 **sv_coef 支持向量系数alpha *rho 判别函数中的b *proA 成对概率信息 *proB 成对概率信息 *sv_indices 记录支持向量在训练数据中的index *label 各类的标签 *nSV 各类的支持向量数 free_SV 若model由svm_load_model函数生成则为1，若为svm_train生成则为0 svm.cpp文件解析下图为svm.cpp中的类继承和组合情况（实现表示继承关系，虚线表示组合关系）：Cache类主要负责运算所涉及的内存的管理，包括申请、释放等。本篇博文主要讲解SVM求解过程，对于Cache类将不予解析。 Kernel类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950class Kernel : public QMatrix &#123;public: Kernel(int l, svm_node * const * x, const svm_parameter&amp; param); virtual ~Kernel(); static double k_function(const svm_node *x, const svm_node *y, const svm_parameter&amp; param); virtual Qfloat *get_Q(int column, int len) const = 0; virtual double *get_QD() const = 0; virtual void swap_index(int i, int j) const // no so const... &#123; swap(x[i], x[j]); if (x_square) swap(x_square[i], x_square[j]); &#125;protected: double (Kernel::*kernel_function)(int i, int j) const;private: const svm_node **x; double *x_square; // svm_parameter const int kernel_type; const int degree; const double gamma; const double coef0; static double dot(const svm_node *px, const svm_node *py); double kernel_linear(int i, int j) const &#123; return dot(x[i], x[j]); &#125; double kernel_poly(int i, int j) const &#123; return powi(gamma*dot(x[i], x[j]) + coef0, degree); &#125; double kernel_rbf(int i, int j) const &#123; return exp(-gamma * (x_square[i] + x_square[j] - 2 * dot(x[i], x[j]))); &#125; double kernel_sigmoid(int i, int j) const &#123; return tanh(gamma*dot(x[i], x[j]) + coef0); &#125; double kernel_precomputed(int i, int j) const &#123; return x[i][(int)(x[j][0].value)].value; &#125;&#125;; 成员变量 Parameter Interpretation svm_node **x 训练样本数据 *x_square x[i]^T*x[i]，使用RBF核会用到 kernel_type 核函数类型 degree svm_parameter gamma svm_parameter coef0 svm_parameter 成员函数Kernel(int l, svm_node * const * x, const svm_parameter&amp; param);构造函数。初始化类中的部分常量、指定核函数、克隆样本数据。 12345678910111213141516171819202122232425262728293031323334Kernel::Kernel(int l, svm_node * const * x_, const svm_parameter&amp; param) :kernel_type(param.kernel_type), degree(param.degree), gamma(param.gamma), coef0(param.coef0)&#123; switch (kernel_type) //根据kernel_type的不同定义相应的函数kernel_function() &#123; case LINEAR: kernel_function = &amp;Kernel::kernel_linear; break; case POLY: kernel_function = &amp;Kernel::kernel_poly; break; case RBF: kernel_function = &amp;Kernel::kernel_rbf; break; case SIGMOID: kernel_function = &amp;Kernel::kernel_sigmoid; break; case PRECOMPUTED: kernel_function = &amp;Kernel::kernel_precomputed; break; &#125; clone(x, x_, l); if (kernel_type == RBF) //如果使用RBF 核函数，则计算x_sqare[i]，即x[i]^T*x[i] &#123; x_square = new double[l]; for (int i = 0; i&lt;l; i++) x_square[i] = dot(x[i], x[i]); &#125; else x_square = 0;&#125; static double dot(const svm_node *px, const svm_node *py);点乘函数，点乘两个样本数据，按svm_node 中index (一般为特征)进行运算，一般来说，index为1，2，…直到-1。返回点乘总和。例如：x1={1,2,3} ,x2={4,5,6}总和为sum=1*4+2*5+3*6;在svm_node[3]中存储index=-1时，停止计算。 123456789101112131415161718192021double Kernel::dot(const svm_node *px, const svm_node *py)&#123; double sum = 0; while (px-&gt;index != -1 &amp;&amp; py-&gt;index != -1) &#123; if (px-&gt;index == py-&gt;index) &#123; sum += px-&gt;value * py-&gt;value; ++px; ++py; &#125; else &#123; if (px-&gt;index &gt; py-&gt;index) ++py; else ++px; &#125; &#125; return sum;&#125; static double k_function(const svm_node *x, const svm_node *y, const svm_parameter&amp; param);功能类似kernel_function,不过kerel_function用于训练，k_function用于预测。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758double Kernel::k_function(const svm_node *x, const svm_node *y, const svm_parameter&amp; param) //输入数据为两个数据样本，其中一个为训练样本一个为测试样本&#123; switch (param.kernel_type) &#123; case LINEAR: return dot(x, y); case POLY: return powi(param.gamma*dot(x, y) + param.coef0, param.degree); case RBF: &#123; double sum = 0; while (x-&gt;index != -1 &amp;&amp; y-&gt;index != -1) &#123; if (x-&gt;index == y-&gt;index) &#123; double d = x-&gt;value - y-&gt;value; sum += d * d; ++x; ++y; &#125; else &#123; if (x-&gt;index &gt; y-&gt;index) &#123; sum += y-&gt;value * y-&gt;value; ++y; &#125; else &#123; sum += x-&gt;value * x-&gt;value; ++x; &#125; &#125; &#125; while (x-&gt;index != -1) &#123; sum += x-&gt;value * x-&gt;value; ++x; &#125; while (y-&gt;index != -1) &#123; sum += y-&gt;value * y-&gt;value; ++y; &#125; return exp(-param.gamma*sum); &#125; case SIGMOID: return tanh(param.gamma*dot(x, y) + param.coef0); case PRECOMPUTED: //x: test (validation), y: SV return x[(int)(y-&gt;value)].value; default: return 0; // Unreachable &#125;&#125; 其中RBF部分很有讲究。因为存储时，0值不保留。如果所有0值都保留，第一个while就可以都做完了；如果第一个while做不完，在x，y中任意一个出现index＝-1，第一个while就停止，剩下的代码中两个while只会有一个工作，该循环直接把剩下的计算做完。 virtual Qfloat *get_Q(int column, int len);纯虚函数，将来在子类中实现(如class SVR_Q)，计算Q值。相当重要的函数。 1virtual Qfloat *get_Q(int column, int len) const = 0; virtual void swap_index(int i, int j);虚函数，x[i]和x[j]中所存储指针的内容。如果x_square不为空，则交换相应的内容。 12345virtual void swap_index(int i, int j) const // no so const... &#123; swap(x[i], x[j]); if (x_square) swap(x_square[i], x_square[j]); &#125; virtual double *get_QD();纯虚函数，将来在子类中实现(如class SVR_Q),计算Q[i,i]值。 1virtual Qfloat *get_Q(int column, int len) const = 0; double (Kernel::*kernel_function)(int i, int j)；函数指针，根据相应的核函数类型，来决定所使用的函数。在计算矩阵Q时使用。 1double (Kernel::*kernel_function)(int i, int j) const; Solver类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556class Solver &#123;public: Solver() &#123;&#125;; virtual ~Solver() &#123;&#125;; struct SolutionInfo &#123; double obj; double rho; double upper_bound_p; double upper_bound_n; double r; // for Solver_NU &#125;; void Solve(int l, const QMatrix&amp; Q, const double *p_, const schar *y_, double *alpha_, double Cp, double Cn, double eps, SolutionInfo* si, int shrinking);protected: int active_size; schar *y; double *G; // gradient of objective function enum &#123; LOWER_BOUND, UPPER_BOUND, FREE &#125;; char *alpha_status; // LOWER_BOUND, UPPER_BOUND, FREE double *alpha; const QMatrix *Q; const double *QD; double eps; double Cp, Cn; double *p; int *active_set; double *G_bar; // gradient, if we treat free variables as 0 int l; bool unshrink; // XXX double get_C(int i) &#123; return (y[i] &gt; 0) ? Cp : Cn; &#125; void update_alpha_status(int i) &#123; if (alpha[i] &gt;= get_C(i)) alpha_status[i] = UPPER_BOUND; else if (alpha[i] &lt;= 0) alpha_status[i] = LOWER_BOUND; else alpha_status[i] = FREE; &#125; bool is_upper_bound(int i) &#123; return alpha_status[i] == UPPER_BOUND; &#125; bool is_lower_bound(int i) &#123; return alpha_status[i] == LOWER_BOUND; &#125; bool is_free(int i) &#123; return alpha_status[i] == FREE; &#125; void swap_index(int i, int j); void reconstruct_gradient(); virtual int select_working_set(int &amp;i, int &amp;j); virtual double calculate_rho(); virtual void do_shrinking();private: bool be_shrunk(int i, double Gmax1, double Gmax2);&#125;; 成员变量结构体SolutionInfo为求解优化中的参数信息。 各参数解释如下： Parameter Interpretation SolutionInfo.obj 求解优化过程中的目标函数值 SolutionInfo.rho 判别函数中的b SolutionInfo.upper_bound_p 对于不平衡数据集，该值对应惩罚因子Cp SolutionInfo.upper_bound_n 对于不平衡数据集，该值对应惩罚因子Cn SolutionInfo.r 用于Solver_NU active_size 计算时实际参加运算的样本数目，经过shrink处理后，该数目会小于全部样本总数。 *y 样本所属类别，该值只取+1/-1 。虽然可以处理多类，最终是用两类SVM 完成的。 *G 梯度G=Qα+P *alpha_status α[i]的状态，根据情况分为α[i]≤0,α[i]≥c和0&lt;α[i]&lt;\c,分别对应内部点(非SV)，错分点(BSV)和支持向量(SV)。 *alpha α[i] *Q 对应公式中Q的某一列 *QD 对应公式中的Q[i][i] eps 停止条件的误差限 Cp，Cn 对应不平衡数据的惩罚因子，若不为不平数据或是对于SVR来说Cp=Cn=C *p 对应梯度公式中的p，即SVR中的间隔带epsilon *active_set active对应的index *G_bar sum(C*Q) l 数据样本个数 unshrink 是否被压缩 成员函数double get_C(int i)；返回对应于样本的C。设置不同的Cp 和Cn 是为了处理数据的不平衡。见[1]中的Unbalanced data.对于一般样本数据Cp=Cn。 1234double get_C(int i) &#123; return (y[i] &gt; 0) ? Cp : Cn; &#125; void swap_index(int i, int j);完全交换样本i和样本j的内容，包括所申请的内存的地址。 12345678910111213void Solver::swap_index(int i, int j)&#123; Q-&gt;swap_index(i, j); swap(y[i], y[j]); swap(G[i], G[j]); swap(alpha_status[i], alpha_status[j]); swap(alpha[i], alpha[j]); swap(p[i], p[j]); swap(active_set[i], active_set[j]); swap(G_bar[i], G_bar[j]);&#125;template &lt;class T&gt; static inline void swap(T&amp; x, T&amp; y) &#123; T t = x; x = y; y = t; &#125; void reconstruct_gradient();重新计算梯度。 1234567891011121314151617181920212223242526272829303132333435363738394041void Solver::reconstruct_gradient()&#123; // reconstruct inactive elements of G from G_bar and free variables if (active_size == l) return; int i, j; int nr_free = 0; for (j = active_size; j&lt;l; j++) G[j] = G_bar[j] + p[j]; for (j = 0; j&lt;active_size; j++) if (is_free(j)) nr_free++; if (2 * nr_free &lt; active_size) info("\nWARNING: using -h 0 may be faster\n"); if (nr_free*l &gt; 2 * active_size*(l - active_size)) &#123; for (i = active_size; i&lt;l; i++) &#123; const Qfloat *Q_i = Q-&gt;get_Q(i, active_size); for (j = 0; j&lt;active_size; j++) if (is_free(j)) G[i] += alpha[j] * Q_i[j]; &#125; &#125; else &#123; for (i = 0; i&lt;active_size; i++) if (is_free(i)) &#123; const Qfloat *Q_i = Q-&gt;get_Q(i, l); double alpha_i = alpha[i]; for (j = active_size; j&lt;l; j++) G[j] += alpha_i * Q_i[j]; &#125; &#125;&#125; G_bar[i]在初始化时并未加入p[i]，所以程序首先增加p[i]。Shrink后依然参加运算的样本位于active_size和l-1位置上。在0～active_size之间的alpha[i]如果在区间(0,c)上，才有必要更新相应的active_size和l-1位置上的样本的梯度。 virtual void do_shrinking();对样本集做缩减。当0&lt;α&lt;C时(还有两种情况),程序认为该样本可以不参加下次迭代。(0&lt;α&lt;C时，为内部点)程序会减小active_size，为内部点增加位置。active_size表明了不可以参加下次迭代的样本的最小标签号，在active_size与l之间的元素都对分类没有贡献。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960void Solver::do_shrinking()&#123; int i; double Gmax1 = -INF; // max &#123; -y_i * grad(f)_i | i in I_up(\alpha) &#125; double Gmax2 = -INF; // max &#123; y_i * grad(f)_i | i in I_low(\alpha) &#125; // find maximal violating pair first for (i = 0; i&lt;active_size; i++) &#123; if (y[i] == +1) &#123; if (!is_upper_bound(i)) // &lt; C &#123; if (-G[i] &gt;= Gmax1) Gmax1 = -G[i]; &#125; if (!is_lower_bound(i)) &#123; if (G[i] &gt;= Gmax2) Gmax2 = G[i]; &#125; &#125; else &#123; if (!is_upper_bound(i)) &#123; if (-G[i] &gt;= Gmax2) Gmax2 = -G[i]; &#125; if (!is_lower_bound(i)) &#123; if (G[i] &gt;= Gmax1) Gmax1 = G[i]; &#125; &#125; &#125; //如果程序在缩减一次后没有达到结束条件，就重新构造梯度矢量，并再缩减一次。 if (unshrink == false &amp;&amp; Gmax1 + Gmax2 &lt;= eps * 10) &#123; unshrink = true; reconstruct_gradient(); active_size = l; info("*"); &#125; //程序中active_size--是为了消除交换后的影响，使重新换来的样本也被检查一次。 for (i = 0; i&lt;active_size; i++) if (be_shrunk(i, Gmax1, Gmax2)) &#123; active_size--; while (active_size &gt; i) &#123; if (!be_shrunk(active_size, Gmax1, Gmax2)) &#123; swap_index(i, active_size); break; &#125; active_size--; &#125; &#125;&#125; virtual int select_working_set(int &amp;i, int &amp;j);该函数求解出违反KKT条件最严重的目标对i与j。我们先来了解一下working set的选择原理。参考文献[3]。 选择iSVM的对偶问题为： SVM收敛的充分必要条件(KKT条件)为： 对(1)式求导可以得到：①yi=1，αi&lt;C，由(2)和(3)可得： ②yi=-1，αi&gt;0，由(2)和(3)可得： ③yi=-1，αi&lt;C，由(2)和(3)可得： ④yi=1，αi&gt;0，由(2)和(3)可得： 对式(4)、(5)、(6)、(7)进行约简得到式(8): 可以发现，(4)和(5)都是b大于某个数，(6)和(7)都是b小于某个数。因为b是个常量，那么根据上述条件，我们可以得到以下结论，在合理的αi和αj下，有： 我们就是要从中挑选违反上述条件的αi和αj，来进行重新的迭代和更新，使得所有的αi和αj都满足上述条件。那么我们可以很容易得到违反条件为： 则根据式(8)中关于i的选择就可以明白select_working_set函数中关于选择i的部分了。 选择j当yiyjK(i,j)为半正定矩阵时，当且仅当待优化乘子为“违反对”时，目标函数是严格递减的。LibSVM在做选择的时候，采用的是second order information方法。那么我们挑选出了i之后，剩下的任务就是挑选出既是“违反对”同时使目标函数值最小。补充一下：挑选了“违反对”，自然就使得目标函数自然递减了，那么我们挑选目标函数最小，自然使得迭代速度加快。这是我们希望看到的结果。 使用泰勒展开式： 则优化问题变为： 由约束条件可知： 因为0≤α≤c,所以当α取到极值的时候，d的取值是有限制的，使得最终的α+d的值不会超出α取值范围。 则原优化问题可转换为下述优化问题： 最小值为： 证明如下(可参考文献[3]的Theorem 3)： 结论貌似挺复杂的，其实不然，仔细观察发现式(13)其实就是一个一元二次函数，对其求极值，得该函数的最小值。 下面我们来看一下代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100int Solver::select_working_set(int &amp;out_i, int &amp;out_j)&#123; // return i,j such that // i: maximizes -y_i * grad(f)_i, i in I_up(\alpha) // j: minimizes the decrease of obj value // (if quadratic coefficeint &lt;= 0, replace it with tau) // -y_j*grad(f)_j &lt; -y_i*grad(f)_i, j in I_low(\alpha) double Gmax = -INF; //-yi*G(alphai) double Gmax2 = -INF; //yj*G(alphaj) int Gmax_idx = -1; int Gmin_idx = -1; double obj_diff_min = INF; //寻找working set B中的i for (int t = 0; t&lt;active_size; t++) if (y[t] == +1) &#123; if (!is_upper_bound(t)) //对应于yi=1,alphai&lt;c if (-G[t] &gt;= Gmax) &#123; Gmax = -G[t]; //寻找最大的-yi*G(alphai)，以使违反条件最严重 Gmax_idx = t; &#125; &#125; else &#123; if (!is_lower_bound(t)) //对应于yi=1,alphai&gt;0 if (G[t] &gt;= Gmax) &#123; Gmax = G[t]; Gmax_idx = t; &#125; &#125; int i = Gmax_idx; //得到i const Qfloat *Q_i = NULL; if (i != -1) // NULL Q_i not accessed: Gmax=-INF if i=-1 Q_i = Q-&gt;get_Q(i, active_size); //寻找working set B中的j for (int j = 0; j&lt;active_size; j++) &#123; if (y[j] == +1) &#123; if (!is_lower_bound(j)) &#123; double grad_diff = Gmax + G[j]; //分子(-yi*Gi+yj*Gj) if (G[j] &gt;= Gmax2) //寻找最小的-yj*G(alphaj) Gmax2 = G[j]; if (grad_diff &gt; 0) //保证不满足KKT条件 &#123; double obj_diff; double quad_coef = QD[i] + QD[j] - 2.0*y[i] * Q_i[j]; //分母(Kii+Kjj-2*Kij),注意Kij和Qij的关系(SVR_Q类中会讲) if (quad_coef &gt; 0) obj_diff = -(grad_diff*grad_diff) / quad_coef; else obj_diff = -(grad_diff*grad_diff) / TAU; //当quad_coef小于0时令其等于一个很小很小的值。 if (obj_diff &lt;= obj_diff_min) &#123; Gmin_idx = j; obj_diff_min = obj_diff; &#125; &#125; &#125; &#125; else &#123; if (!is_upper_bound(j)) &#123; double grad_diff = Gmax - G[j]; if (-G[j] &gt;= Gmax2) Gmax2 = -G[j]; if (grad_diff &gt; 0) &#123; double obj_diff; double quad_coef = QD[i] + QD[j] + 2.0*y[i] * Q_i[j]; if (quad_coef &gt; 0) obj_diff = -(grad_diff*grad_diff) / quad_coef; else obj_diff = -(grad_diff*grad_diff) / TAU; if (obj_diff &lt;= obj_diff_min) &#123; Gmin_idx = j; obj_diff_min = obj_diff; &#125; &#125; &#125; &#125; &#125; if (Gmax + Gmax2 &lt; eps || Gmin_idx == -1) //达到停止条件或再没有需要优化的alpha，表示已经完全优化 return 1; out_i = Gmax_idx; out_j = Gmin_idx; return 0;&#125; void Solve(int l, const QMatrix&amp; Q, const double *p_, const schar *y_, double *alpha_, double Cp, double Cn, double eps, SolutionInfo* si, int shrinking);Solve函数用于求解更新alpha，下面讲解一下其求解原理，主要是SMO算法原理。这里主要还是以C-SVC为例，在后面讲解SVR_Q类时会解释如何将其扩展至回归分析。 SVM寻找超平面的公式为： 其对偶问题为： 将其表示为矩阵形式可变换为： 其中C&gt;0为上界，e是数值全为1的行向量，Q是l*l的半正定矩阵，Qij=yi*yj*K(i,j)，K(i,j)=φ(Xi)^T*φ(Xj)为核函数。 当然，这只是LIBSVM中的C-SVC的目标公式，LIBSVM采用的是更加通用的目标公式： 其中p是长度为l的行向量，△为常数。 其求导为： 于是令aij = Kii+Kjj-2*Kij，假设选定的working set B为i和j，将其带入上式。（见文献[2]的Algorithm 1）当aij&gt;0时得： 当aij≤0时，约束同上式，令： 上式加的一项看似复杂，其实就是函数select_working_set中写的，当aij小于0时令其等于一个很小很小的值。 工作集i,j的选择参见select_working_set函数的讲解。 αi,αj的更新参考文献[2]的“5 Unbalanced Data”。 令： 则问题： 可转化为问题： 进而求解出di,dj可以得到更新后的α，即： 其中： 以不考虑非均衡样本为例(即Cp=Cn)。当yi≠yj时： 当yi=yj时： 梯度G的更新G[α(k)] = Q[α(k)] + pG[α(k+1)] = Q[α(k+1)] + p则：G[α(k+1)] = G[α(k)] + Q[α(k+1)-α(k)] G_bar的更新G_bar[i] = {C * sum(Q[i,j]) while α[j]=C} i = 1,2,3,… l因此，若α更新前后状态(alpha_status)不变，如都为C或都小于C，则G_bar不变。否则：①迭代前不为C，迭代后为C，则：G_bar(k+1)[i] = {C * sum(Q[i,j]) while α[j]=C}②迭代前为C，迭代后不为C，则：G_bar(k+1)[i] = G_bar(k)[i] - {C * sum(Q[i,j]) while α[j]=C} 下面我们开始看代码。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284void Solver::Solve(int l, const QMatrix&amp; Q, const double *p_, const schar *y_, double *alpha_, double Cp, double Cn, double eps, SolutionInfo* si, int shrinking)&#123; this-&gt;l = l; this-&gt;Q = &amp;Q; QD = Q.get_QD(); clone(p, p_, l); clone(y, y_, l); clone(alpha, alpha_, l); this-&gt;Cp = Cp; this-&gt;Cn = Cn; this-&gt;eps = eps; unshrink = false; // initialize alpha_status &#123; alpha_status = new char[l]; for (int i = 0; i&lt;l; i++) update_alpha_status(i); &#125; // initialize active set (for shrinking) &#123; active_set = new int[l]; for (int i = 0; i&lt;l; i++) active_set[i] = i; active_size = l; &#125; // initialize gradient，根据梯度定义公式进行初始化 &#123; G = new double[l]; G_bar = new double[l]; int i; for (i = 0; i&lt;l; i++) &#123; G[i] = p[i]; G_bar[i] = 0; &#125; for (i = 0; i&lt;l; i++) if (!is_lower_bound(i)) &#123; const Qfloat *Q_i = Q.get_Q(i, l); double alpha_i = alpha[i]; int j; for (j = 0; j&lt;l; j++) G[j] += alpha_i * Q_i[j]; if (is_upper_bound(i)) for (j = 0; j&lt;l; j++) G_bar[j] += get_C(i) * Q_i[j]; &#125; &#125; // optimization step int iter = 0; int max_iter = max(10000000, l&gt;INT_MAX / 100 ? INT_MAX : 100 * l); int counter = min(l, 1000) + 1; while (iter &lt; max_iter) &#123; // show progress and do shrinking if (--counter == 0) &#123; counter = min(l, 1000); if (shrinking) do_shrinking(); info("do shrinking.\n"); &#125; int i, j; if (select_working_set(i, j) != 0) &#123; // reconstruct the whole gradient reconstruct_gradient(); // reset active set size and check active_size = l; info("reconstruct G*\n"); if (select_working_set(i, j) != 0) &#123; info("======break======"); break; &#125; else counter = 1; // do shrinking next iteration &#125; ++iter; // update alpha[i] and alpha[j], handle bounds carefully const Qfloat *Q_i = Q.get_Q(i, active_size); const Qfloat *Q_j = Q.get_Q(j, active_size); double C_i = get_C(i); double C_j = get_C(j); double old_alpha_i = alpha[i]; double old_alpha_j = alpha[j]; if (y[i] != y[j]) //# yi,yj异号 &#123; double quad_coef = QD[i] + QD[j] + 2 * Q_i[j]; //最后一个为+号因为Qij为kij*y[i]*y[j] if (quad_coef &lt;= 0) quad_coef = TAU; double delta = (-G[i] - G[j]) / quad_coef; //alpha改变量 double diff = alpha[i] - alpha[j]; //根据此项判断alpha(i)-alpha(j)=constant与约束框(0~c)的交点 alpha[i] += delta; alpha[j] += delta; if (diff &gt; 0) &#123; if (alpha[j] &lt; 0) &#123; alpha[j] = 0; alpha[i] = diff; &#125; &#125; else &#123; if (alpha[i] &lt; 0) &#123; alpha[i] = 0; alpha[j] = -diff; &#125; &#125; if (diff &gt; C_i - C_j) &#123; if (alpha[i] &gt; C_i) &#123; alpha[i] = C_i; alpha[j] = C_i - diff; &#125; &#125; else &#123; if (alpha[j] &gt; C_j) &#123; alpha[j] = C_j; alpha[i] = C_j + diff; &#125; &#125; &#125; else &#123; double quad_coef = QD[i] + QD[j] - 2 * Q_i[j]; if (quad_coef &lt;= 0) quad_coef = TAU; double delta = (G[i] - G[j]) / quad_coef; double sum = alpha[i] + alpha[j]; alpha[i] -= delta; alpha[j] += delta; if (sum &gt; C_i) &#123; if (alpha[i] &gt; C_i) &#123; alpha[i] = C_i; alpha[j] = sum - C_i; &#125; &#125; else &#123; if (alpha[j] &lt; 0) &#123; alpha[j] = 0; alpha[i] = sum; &#125; &#125; if (sum &gt; C_j) &#123; if (alpha[j] &gt; C_j) &#123; alpha[j] = C_j; alpha[i] = sum - C_j; &#125; &#125; else &#123; if (alpha[i] &lt; 0) &#123; alpha[i] = 0; alpha[j] = sum; &#125; &#125; &#125; // update G double delta_alpha_i = alpha[i] - old_alpha_i; double delta_alpha_j = alpha[j] - old_alpha_j; for (int k = 0; k&lt;active_size; k++) &#123; G[k] += Q_i[k] * delta_alpha_i + Q_j[k] * delta_alpha_j; &#125; // update alpha_status and G_bar &#123; bool ui = is_upper_bound(i); bool uj = is_upper_bound(j); update_alpha_status(i); update_alpha_status(j); int k; if (ui != is_upper_bound(i)) &#123; Q_i = Q.get_Q(i, l); if (ui) for (k = 0; k&lt;l; k++) G_bar[k] -= C_i * Q_i[k]; else for (k = 0; k&lt;l; k++) G_bar[k] += C_i * Q_i[k]; &#125; if (uj != is_upper_bound(j)) &#123; Q_j = Q.get_Q(j, l); if (uj) for (k = 0; k&lt;l; k++) G_bar[k] -= C_j * Q_j[k]; else for (k = 0; k&lt;l; k++) G_bar[k] += C_j * Q_j[k]; &#125; &#125; printf("i:%d, j:%d, alpha_i:%f, alpha_j:%f\n", i, j, alpha[i], alpha[j]); &#125; if (iter &gt;= max_iter) &#123; if (active_size &lt; l) &#123; // reconstruct the whole gradient to calculate objective value reconstruct_gradient(); active_size = l; info("*"); &#125; fprintf(stderr, "\nWARNING: reaching max number of iterations\n"); &#125; // calculate rho si-&gt;rho = calculate_rho(); // calculate objective value &#123; double v = 0; int i; for (i = 0; i&lt;l; i++) v += alpha[i] * (G[i] + p[i]); si-&gt;obj = v / 2; //目标值为(alpha^T*Q*alpha + p^T*alpha) &#125; // put back the solution &#123; for (int i = 0; i&lt;l; i++) alpha_[active_set[i]] = alpha[i]; &#125; // juggle everything back /*&#123; for(int i=0;i&lt;l;i++) while(active_set[i] != i) swap_index(i,active_set[i]); // or Q.swap_index(i,active_set[i]); &#125;*/ si-&gt;upper_bound_p = Cp; si-&gt;upper_bound_n = Cn; info("\noptimization finished, #iter = %d\n", iter); /*for (int g = 0; g &lt; l/2; g++) &#123; printf("alpha_%d:%f\n", g, (alpha[g]-alpha[g+l/2])); &#125;*/ delete[] p; delete[] y; delete[] alpha; delete[] alpha_status; delete[] active_set; delete[] G; delete[] G_bar;&#125; virtual double calculate_rho();该函数用于计算判别函数中的b(rho为b的相反数)，参考文献[2]的3.6。这里仅写出结果：当yi=1时：假设0&lt;αi&lt;C，则r1 = G[α](i)为避免出现数值错误，一般将其写成平均值：如果没有这样的αi，则r1必须满足：此时将ri取为范围中点。当yi=-1时，计算过程类似，得到r2。 得到r1、r2后，通过计算得到： 12345678910111213141516171819202122232425262728293031323334353637double Solver::calculate_rho()&#123; double r; int nr_free = 0; double ub = INF, lb = -INF, sum_free = 0; for (int i = 0; i&lt;active_size; i++) &#123; double yG = y[i] * G[i]; if (is_upper_bound(i)) &#123; if (y[i] == -1) ub = min(ub, yG); else lb = max(lb, yG); &#125; else if (is_lower_bound(i)) &#123; if (y[i] == +1) ub = min(ub, yG); else lb = max(lb, yG); &#125; else &#123; ++nr_free; sum_free += yG; &#125; &#125; if (nr_free&gt;0) r = sum_free / nr_free; else r = (ub + lb) / 2; return r;&#125; SVR_Q类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374class SVR_Q : public Kernel&#123;public: SVR_Q(const svm_problem&amp; prob, const svm_parameter&amp; param) :Kernel(prob.l, prob.x, param) &#123; l = prob.l; cache = new Cache(l, (long int)(param.cache_size*(1 &lt;&lt; 20))); QD = new double[2 * l]; sign = new schar[2 * l]; index = new int[2 * l]; for (int k = 0; k&lt;l; k++) &#123; sign[k] = 1; sign[k + l] = -1; index[k] = k; index[k + l] = k; QD[k] = (this-&gt;*kernel_function)(k, k); QD[k + l] = QD[k]; &#125; buffer[0] = new Qfloat[2 * l]; buffer[1] = new Qfloat[2 * l]; next_buffer = 0; &#125; void swap_index(int i, int j) const &#123; swap(sign[i], sign[j]); swap(index[i], index[j]); swap(QD[i], QD[j]); &#125; Qfloat *get_Q(int i, int len) const &#123; Qfloat *data; int j, real_i = index[i]; if (cache-&gt;get_data(real_i, &amp;data, l) &lt; l) &#123; for (j = 0; j&lt;l; j++) data[j] = (Qfloat)(this-&gt;*kernel_function)(real_i, j); &#125; // reorder and copy Qfloat *buf = buffer[next_buffer]; next_buffer = 1 - next_buffer; schar si = sign[i]; for (j = 0; j&lt;len; j++) buf[j] = (Qfloat)si * (Qfloat)sign[j] * data[index[j]]; return buf; &#125; double *get_QD() const &#123; return QD; &#125; ~SVR_Q() &#123; delete cache; delete[] sign; delete[] index; delete[] buffer[0]; delete[] buffer[1]; delete[] QD; &#125;private: int l; Cache *cache; schar *sign; int *index; mutable int next_buffer; Qfloat *buffer[2]; double *QD;&#125;; 成员变量主要参数解释如下： Parameter Interpretation *sign 同SVC_Q中的y，即为公式中的y。sign[i]=1,sign[i+l]=-1,i=1,2,3,…,l 成员函数SVR_Q(const svm_problem&amp; prob, const svm_parameter&amp; param):Kernel(prob.l, prob.x, param);初始化有关SVR的计算参数。与SVC不同的是优化公式中的y并不是SVR样本数据的目标值，优化公式中的l为两倍的SVR数据样本数量，详见solve_epsilon_svr函数解析。 1234567891011121314151617181920212223242526SVR_Q(const svm_problem&amp; prob, const svm_parameter&amp; param) :Kernel(prob.l, prob.x, param) &#123; l = prob.l; //l为样本数据的数量 cache = new Cache(l, (long int)(param.cache_size*(1 &lt;&lt; 20))); //对于SVR而言需要开辟2*l的空间 QD = new double[2 * l]; sign = new schar[2 * l]; index = new int[2 * l]; for (int k = 0; k&lt;l; k++) &#123; //sign[i]=1,sign[i+l]=-1,i=1,2,3,...,l sign[k] = 1; sign[k + l] = -1; index[k] = k; index[k + l] = k; QD[k] = (this-&gt;*kernel_function)(k, k); QD[k + l] = QD[k]; &#125; buffer[0] = new Qfloat[2 * l]; buffer[1] = new Qfloat[2 * l]; next_buffer = 0; &#125; Qfloat *get_Q(int i, int len) const;计算SVR公式中所使用的Q[i]，此处为第i列，不过一般而言Q[i,j]=Q[j,i]。 123456789101112131415161718Qfloat *get_Q(int i, int len) const&#123; Qfloat *data; int j, real_i = index[i]; if (cache-&gt;get_data(real_i, &amp;data, l) &lt; l) &#123; for (j = 0; j&lt;l; j++) data[j] = (Qfloat)(this-&gt;*kernel_function)(real_i, j); //计算得到K[i,j] &#125; // reorder and copy Qfloat *buf = buffer[next_buffer]; next_buffer = 1 - next_buffer; schar si = sign[i]; for (j = 0; j&lt;len; j++) buf[j] = (Qfloat)si * (Qfloat)sign[j] * data[index[j]]; //为了与Solver类中的公式相匹配，此处定义Q[i,j]=sign[i]*sign[j]*K[i,j] return buf;&#125; static void solve_epsilon_svr(const svm_problem *prob, const svm_parameter *param, double *alpha, Solver::SolutionInfo* si)该函数用于计算优化公式中的p，并定义Solver中的y与α，调用Solver类。 epsilon-SVR原始公式为： 其对偶式为： 其中： 决策函数为： 将其化为矩阵形式： 其中y为2l*1的矩阵，yt=1，t=1,…,l; yt=-1，t=l+1,…,2l. 将上式与前述的通用目标公式相比较，记上标t为通用公式的参数，则可知： 12345678910111213141516171819202122232425262728293031323334353637static void solve_epsilon_svr( const svm_problem *prob, const svm_parameter *param, double *alpha, Solver::SolutionInfo* si)&#123; int l = prob-&gt;l; double *alpha2 = new double[2 * l]; double *linear_term = new double[2 * l]; schar *y = new schar[2 * l]; //新定义了y值，对应Solver的y int i; for (i = 0; i&lt;l; i++) &#123; alpha2[i] = 0; linear_term[i] = param-&gt;p - prob-&gt;y[i]; //epsilon*e-z,epsilon为间隔带，e为全为1的行向量，z为样本数据的目标值 y[i] = 1; alpha2[i + l] = 0; linear_term[i + l] = param-&gt;p + prob-&gt;y[i]; //epsilon*e+z y[i + l] = -1; &#125; Solver s; s.Solve(2 * l, SVR_Q(*prob, *param), linear_term, y, alpha2, param-&gt;C, param-&gt;C, param-&gt;eps, si, param-&gt;shrinking); double sum_alpha = 0; for (i = 0; i&lt;l; i++) &#123; alpha[i] = alpha2[i] - alpha2[i + l]; //将alpha[i]-alpha[i+1]得到数据样本x前的最终系数 sum_alpha += fabs(alpha[i]); &#125; info("nu = %f\n", sum_alpha / (param-&gt;C*l)); delete[] alpha2; delete[] linear_term; delete[] y;&#125; static decision_function svm_train_one(const svm_problem *prob, const svm_parameter *param, double Cp, double Cn)根据kernel_type的不同调用不同的求解函数，并计算支持向量的个数与处于边界的支持向量个数。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556static decision_function svm_train_one( const svm_problem *prob, const svm_parameter *param, double Cp, double Cn)&#123; double *alpha = Malloc(double, prob-&gt;l); Solver::SolutionInfo si; switch (param-&gt;svm_type) &#123; case C_SVC: solve_c_svc(prob, param, alpha, &amp;si, Cp, Cn); break; case NU_SVC: solve_nu_svc(prob, param, alpha, &amp;si); break; case ONE_CLASS: solve_one_class(prob, param, alpha, &amp;si); break; case EPSILON_SVR: solve_epsilon_svr(prob, param, alpha, &amp;si); break; case NU_SVR: solve_nu_svr(prob, param, alpha, &amp;si); break; &#125; info("obj = %f, rho = %f\n", si.obj, si.rho); // output SVs int nSV = 0; int nBSV = 0; for (int i = 0; i&lt;prob-&gt;l; i++) &#123; if (fabs(alpha[i]) &gt; 0) &#123; ++nSV; if (prob-&gt;y[i] &gt; 0) &#123; if (fabs(alpha[i]) &gt;= si.upper_bound_p) ++nBSV; &#125; else &#123; if (fabs(alpha[i]) &gt;= si.upper_bound_n) ++nBSV; &#125; &#125; &#125; info("nSV = %d, nBSV = %d\n", nSV, nBSV); decision_function f; f.alpha = alpha; f.rho = si.rho; return f;&#125; svm_model *svm_train(const svm_problem *prob, const svm_parameter *param)；根据不同svm_type开辟不同空间，最后返回训练好的svm model。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245svm_model *svm_train(const svm_problem *prob, const svm_parameter *param)&#123; svm_model *model = Malloc(svm_model, 1); model-&gt;param = *param; model-&gt;free_sv = 0; // XXX if (param-&gt;svm_type == ONE_CLASS || param-&gt;svm_type == EPSILON_SVR || param-&gt;svm_type == NU_SVR) &#123; // regression or one-class-svm model-&gt;nr_class = 2; model-&gt;label = NULL; model-&gt;nSV = NULL; model-&gt;probA = NULL; model-&gt;probB = NULL; model-&gt;sv_coef = Malloc(double *, 1); /*if (param-&gt;probability &amp;&amp; (param-&gt;svm_type == EPSILON_SVR || param-&gt;svm_type == NU_SVR)) &#123; model-&gt;probA = Malloc(double, 1); model-&gt;probA[0] = svm_svr_probability(prob, param); &#125;*/ decision_function f = svm_train_one(prob, param, 0, 0); model-&gt;rho = Malloc(double, 1); model-&gt;rho[0] = f.rho; int nSV = 0; int i; for (i = 0; i&lt;prob-&gt;l; i++) if (fabs(f.alpha[i]) &gt; 0) ++nSV; model-&gt;l = nSV; model-&gt;SV = Malloc(svm_node *, nSV); model-&gt;sv_coef[0] = Malloc(double, nSV); model-&gt;sv_indices = Malloc(int, nSV); int j = 0; for (i = 0; i&lt;prob-&gt;l; i++) if (fabs(f.alpha[i]) &gt; 0) &#123; model-&gt;SV[j] = prob-&gt;x[i]; model-&gt;sv_coef[0][j] = f.alpha[i]; model-&gt;sv_indices[j] = i + 1; ++j; &#125; free(f.alpha); &#125; else &#123; // classification int l = prob-&gt;l; int nr_class; int *label = NULL; int *start = NULL; int *count = NULL; int *perm = Malloc(int, l); // group training data of the same class svm_group_classes(prob, &amp;nr_class, &amp;label, &amp;start, &amp;count, perm); if (nr_class == 1) info("WARNING: training data in only one class. See README for details.\n"); svm_node **x = Malloc(svm_node *, l); int i; for (i = 0; i&lt;l; i++) x[i] = prob-&gt;x[perm[i]]; // calculate weighted C double *weighted_C = Malloc(double, nr_class); for (i = 0; i&lt;nr_class; i++) weighted_C[i] = param-&gt;C; for (i = 0; i&lt;param-&gt;nr_weight; i++) &#123; int j; for (j = 0; j&lt;nr_class; j++) if (param-&gt;weight_label[i] == label[j]) break; if (j == nr_class) fprintf(stderr, "WARNING: class label %d specified in weight is not found\n", param-&gt;weight_label[i]); else weighted_C[j] *= param-&gt;weight[i]; &#125; // train k*(k-1)/2 models bool *nonzero = Malloc(bool, l); for (i = 0; i&lt;l; i++) nonzero[i] = false; decision_function *f = Malloc(decision_function, nr_class*(nr_class - 1) / 2); double *probA = NULL, *probB = NULL; if (param-&gt;probability) &#123; probA = Malloc(double, nr_class*(nr_class - 1) / 2); probB = Malloc(double, nr_class*(nr_class - 1) / 2); &#125; int p = 0; for (i = 0; i&lt;nr_class; i++) for (int j = i + 1; j&lt;nr_class; j++) &#123; svm_problem sub_prob; int si = start[i], sj = start[j]; int ci = count[i], cj = count[j]; sub_prob.l = ci + cj; sub_prob.x = Malloc(svm_node *, sub_prob.l); sub_prob.y = Malloc(double, sub_prob.l); int k; for (k = 0; k&lt;ci; k++) &#123; sub_prob.x[k] = x[si + k]; sub_prob.y[k] = +1; &#125; for (k = 0; k&lt;cj; k++) &#123; sub_prob.x[ci + k] = x[sj + k]; sub_prob.y[ci + k] = -1; &#125; if (param-&gt;probability) svm_binary_svc_probability(&amp;sub_prob, param, weighted_C[i], weighted_C[j], probA[p], probB[p]); f[p] = svm_train_one(&amp;sub_prob, param, weighted_C[i], weighted_C[j]); for (k = 0; k&lt;ci; k++) if (!nonzero[si + k] &amp;&amp; fabs(f[p].alpha[k]) &gt; 0) nonzero[si + k] = true; for (k = 0; k&lt;cj; k++) if (!nonzero[sj + k] &amp;&amp; fabs(f[p].alpha[ci + k]) &gt; 0) nonzero[sj + k] = true; free(sub_prob.x); free(sub_prob.y); ++p; &#125; // build output model-&gt;nr_class = nr_class; model-&gt;label = Malloc(int, nr_class); for (i = 0; i&lt;nr_class; i++) model-&gt;label[i] = label[i]; model-&gt;rho = Malloc(double, nr_class*(nr_class - 1) / 2); for (i = 0; i&lt;nr_class*(nr_class - 1) / 2; i++) model-&gt;rho[i] = f[i].rho; if (param-&gt;probability) &#123; model-&gt;probA = Malloc(double, nr_class*(nr_class - 1) / 2); model-&gt;probB = Malloc(double, nr_class*(nr_class - 1) / 2); for (i = 0; i&lt;nr_class*(nr_class - 1) / 2; i++) &#123; model-&gt;probA[i] = probA[i]; model-&gt;probB[i] = probB[i]; &#125; &#125; else &#123; model-&gt;probA = NULL; model-&gt;probB = NULL; &#125; int total_sv = 0; int *nz_count = Malloc(int, nr_class); model-&gt;nSV = Malloc(int, nr_class); for (i = 0; i&lt;nr_class; i++) &#123; int nSV = 0; for (int j = 0; j&lt;count[i]; j++) if (nonzero[start[i] + j]) &#123; ++nSV; ++total_sv; &#125; model-&gt;nSV[i] = nSV; nz_count[i] = nSV; &#125; info("Total nSV = %d\n", total_sv); model-&gt;l = total_sv; model-&gt;SV = Malloc(svm_node *, total_sv); model-&gt;sv_indices = Malloc(int, total_sv); p = 0; for (i = 0; i&lt;l; i++) if (nonzero[i]) &#123; model-&gt;SV[p] = x[i]; model-&gt;sv_indices[p++] = perm[i] + 1; &#125; int *nz_start = Malloc(int, nr_class); nz_start[0] = 0; for (i = 1; i&lt;nr_class; i++) nz_start[i] = nz_start[i - 1] + nz_count[i - 1]; model-&gt;sv_coef = Malloc(double *, nr_class - 1); for (i = 0; i&lt;nr_class - 1; i++) model-&gt;sv_coef[i] = Malloc(double, total_sv); p = 0; for (i = 0; i&lt;nr_class; i++) for (int j = i + 1; j&lt;nr_class; j++) &#123; // classifier (i,j): coefficients with // i are in sv_coef[j-1][nz_start[i]...], // j are in sv_coef[i][nz_start[j]...] int si = start[i]; int sj = start[j]; int ci = count[i]; int cj = count[j]; int q = nz_start[i]; int k; for (k = 0; k&lt;ci; k++) if (nonzero[si + k]) model-&gt;sv_coef[j - 1][q++] = f[p].alpha[k]; q = nz_start[j]; for (k = 0; k&lt;cj; k++) if (nonzero[sj + k]) model-&gt;sv_coef[i][q++] = f[p].alpha[ci + k]; ++p; &#125; free(label); free(probA); free(probB); free(count); free(perm); free(start); free(x); free(weighted_C); free(nonzero); for (i = 0; i&lt;nr_class*(nr_class - 1) / 2; i++) free(f[i].alpha); free(f); free(nz_count); free(nz_start); &#125; return model;&#125; double svm_predict_values(const svm_model *model, const svm_node *x, double* dec_values)该函数用于预测单个测试样本数据，因此对于一组测试样本需要调用n次。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475double svm_predict_values(const svm_model *model, const svm_node *x, double* dec_values)&#123; int i; if (model-&gt;param.svm_type == ONE_CLASS || model-&gt;param.svm_type == EPSILON_SVR || model-&gt;param.svm_type == NU_SVR) &#123; double *sv_coef = model-&gt;sv_coef[0]; double sum = 0; for (i = 0; i&lt;model-&gt;l; i++) sum += sv_coef[i] * Kernel::k_function(x, model-&gt;SV[i], model-&gt;param); //对应决策公式的前半部分，即αi*K(xi,x) sum -= model-&gt;rho[0]; //加上决策函数的常数项 *dec_values = sum; if (model-&gt;param.svm_type == ONE_CLASS) return (sum&gt;0) ? 1 : -1; else return sum; &#125; else &#123; int nr_class = model-&gt;nr_class; int l = model-&gt;l; double *kvalue = Malloc(double, l); for (i = 0; i&lt;l; i++) kvalue[i] = Kernel::k_function(x, model-&gt;SV[i], model-&gt;param); int *start = Malloc(int, nr_class); start[0] = 0; for (i = 1; i&lt;nr_class; i++) start[i] = start[i - 1] + model-&gt;nSV[i - 1]; int *vote = Malloc(int, nr_class); for (i = 0; i&lt;nr_class; i++) vote[i] = 0; int p = 0; for (i = 0; i&lt;nr_class; i++) for (int j = i + 1; j&lt;nr_class; j++) &#123; double sum = 0; int si = start[i]; int sj = start[j]; int ci = model-&gt;nSV[i]; int cj = model-&gt;nSV[j]; int k; double *coef1 = model-&gt;sv_coef[j - 1]; double *coef2 = model-&gt;sv_coef[i]; for (k = 0; k&lt;ci; k++) sum += coef1[si + k] * kvalue[si + k]; for (k = 0; k&lt;cj; k++) sum += coef2[sj + k] * kvalue[sj + k]; sum -= model-&gt;rho[p]; dec_values[p] = sum; if (dec_values[p] &gt; 0) ++vote[i]; else ++vote[j]; p++; &#125; int vote_max_idx = 0; for (i = 1; i&lt;nr_class; i++) if (vote[i] &gt; vote[vote_max_idx]) vote_max_idx = i; free(kvalue); free(start); free(vote); return model-&gt;label[vote_max_idx]; &#125;&#125; Reference:[1] Smola A J, Schölkopf B. A tutorial on support vector regression[J]. Statistics &amp; Computing, 2004, volume 14(3):199-222(24).[2] Chang C C, Lin C J. LIBSVM: A library for support vector machines[M]. ACM, 2011.[3] Fan R E, Chen P H, Lin C J, et al. Working Set Selection Using Second Order Information for Training Support Vector Machines[J]. Journal of Machine Learning Research, 2005, 6(4):1889-1918.[4] Svm O F. Sequential Minimal Optimization for SVM[J]. 2007.[5] LibSVM中select_working_set函数：http://blog.csdn.net/le_zhou/article/details/40505465[6] libsvm最新源代码（版本3.21）理解解析（三）：http://blog.csdn.net/xiaoqiangqiangjie/article/details/53886907[7] LibSVM源码剖析（java版）：http://makaidong.com/bentuwuying/21760_40631.html[8] LibSVM-2.6 程序代码注释,上交]]></content>
      <categories>
        <category>SVM</category>
      </categories>
      <tags>
        <tag>Machine learning</tag>
        <tag>Artificial Intelligence</tag>
        <tag>Support Vector Machine</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[P问题、NP问题、NPC问题、NP-hard问题详解]]></title>
    <url>%2F2017%2F09%2F13%2FP%E9%97%AE%E9%A2%98%E3%80%81NP%E9%97%AE%E9%A2%98%E3%80%81NPC%E9%97%AE%E9%A2%98%E3%80%81NP-hard%E9%97%AE%E9%A2%98%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[要理解P问题、NP问题、NPC问题、NP-hard问题，需要先弄懂几个概念： 什么是多项式时间？ 什么是确定性算法？什么是非确定性算法？ 什么是规约/约化？ 多项式时间（Polynomial time）什么是时间复杂度？ 时间复杂度并不是表示一个程序解决问题需要花多少时间，而是当程序所处理的问题规模扩大后，程序需要的时间长度对应增长得有多快。也就是说，对于某一个程序，其处理某一个特定数据的效率不能衡量该程序的好坏，而应该看当这个数据的规模变大到数百倍后，程序运行时间是否还是一样，或者也跟着慢了数百倍，或者变慢了数万倍。 不管数据有多大，程序处理所花的时间始终是那么多的，我们就说这个程序很好，具有$O(1)$的时间复杂度，也称常数级复杂度；数据规模变得有多大，花的时间也跟着变得有多长，比如找n个数中的最大值这个程序的时间复杂度就是$O(n)$，为线性级复杂度，而像冒泡排序、插入排序等，数据扩大2倍，时间变慢4倍的，时间复杂度是$O(n^2)$，为平方级复杂度。还有一些穷举类的算法，所需时间长度成几何阶数上涨，这就是$O(a^n)$的指数级复杂度，甚至$O(n!)$的阶乘级复杂度。 不会存在 $O(2*n^2)$ 的复杂度，因为前面的那个”2”是系数，根本不会影响到整个程序的时间增长。同样地，$O(n^3+n^2)$ 的复杂度也就是$O(n^3)$的复杂度。因此，我们会说，一个$O(0.01*n^3)$的程序的效率比O(100*n^2)的效率低，尽管在n很小的时候，前者优于后者，但后者时间随数据规模增长得慢，最终$O(n^3)$的复杂度将远远超过$O(n^2)$。我们也说，$O(n^{100})$的复杂度小于$O(1.01^n)$的复杂度。 容易看出，前面的几类复杂度被分为两种级别，其中后者的复杂度无论如何都远远大于前者。像$O(1)$,$O(\ln(n))$,$O(n^a)$等，我们把它叫做多项式级复杂度，因为它的规模n出现在底数的位置；另一种像是$O(a^n)$和$O(n!)$等，它是非多项式级的复杂度，其复杂度计算机往往不能承受。当我们在解决一个问题时，我们选择的算法通常都需要是多项式级的复杂度，非多项式级的复杂度需要的时间太多，往往会超时，除非是数据规模非常小。 确定性算法与非确定性算法确定性算法：设A是求解问题B的一个解决算法，在算法的整个执行过程中，每一步都能得到一个确定的解，这样的算法就是确定性算法。 非确定性算法：设A是求解问题B的一个解决算法，它将问题分解成两部分，分别为猜测阶段和验证阶段，其中 猜测阶段：在这个阶段，对问题的一个特定的输入实例x产生一个任意字符串y，在算法的每一次运行时，y的值可能不同，因此，猜测以一种非确定的形式工作。 验证阶段：在这个阶段，用一个确定性算法（有限时间内）验证。①检查在猜测阶段产生的y是否是合适的形式，如果不是，则算法停下来并得到no；② 如果y是合适的形式，则验证它是否是问题的解，如果是，则算法停下来并得到yes，否则算法停下来并得到no。它是验证所猜测的解的正确性。 规约/约化问题A可以约化为问题B，称为“问题A可规约为问题B”，可以理解为问题B的解一定就是问题A的解，因此解决A不会难于解决B。由此可知问题B的时间复杂度一定大于等于问题A。 《算法导论》中有一个例子：现在有两个问题：求解一个一元一次方程和求解一个一元二次方程。那么我们说，前者可以规约为后者，意即知道如何解一个一元二次方程那么一定能解出一元一次方程。我们可以写出两个程序分别对应两个问题，那么我们能找到一个“规则”，按照这个规则把解一元一次方程程序的输入数据变一下，用在解一元二次方程的程序上，两个程序总能得到一样的结果。这个规则即是：两个方程的对应项系数不变，一元二次方程的二次项系数为0。 从规约的定义中我们看到，一个问题规约为另一个问题，时间复杂度增加了，问题的应用范围也增大了。通过对某些问题的不断规约，我们能够不断寻找复杂度更高，但应用范围更广的算法来代替复杂度虽然低，但只能用于很小的一类问题的算法。存在这样一个NP问题，所有的NP问题都可以约化成它。换句话说，只要解决了这个问题，那么所有的NP问题都解决了。这种问题的存在难以置信，并且更加不可思议的是，这种问题不只一个，它有很多个，它是一类问题。这一类问题就是传说中的NPC问题，也就是NP-完全问题。 P类问题、NP类问题、NPC问题、NP难问题 P类问题：能在多项式时间内可解的问题。 NP类问题：在多项式时间内“可验证”的问题。也就是说，不能判定这个问题到底有没有解，而是猜出一个解来在多项式时间内证明这个解是否正确。即该问题的猜测过程是不确定的，而对其某一个解的验证则能够在多项式时间内完成。P类问题属于NP问题，但NP类问题不一定属于P类问题。 NPC问题：存在这样一个NP问题，所有的NP问题都可以约化成它。换句话说，只要解决了这个问题，那么所有的NP问题都解决了。其定义要满足2个条件： 它是一个NP问题； 所有NP问题都能规约到它。 NP难问题：NP-Hard问题是这样一种问题，它满足NPC问题定义的第二条但不一定要满足第一条（就是说，NP-Hard问题要比 NPC问题的范围广，NP-Hard问题没有限定属于NP），即所有的NP问题都能约化到它，但是他不一定是一个NP问题。NP-Hard问题同样难以找到多项式的算法，但它不列入我们的研究范围，因为它不一定是NP问题。即使NPC问题发现了多项式级的算法，NP-Hard问题有可能仍然无法得到多项式级的算法。事实上，由于NP-Hard放宽了限定条件，它将有可能比所有的NPC问题的时间复杂度更高从而更难以解决。以上四个问题之间的关系如下图所示： P=NP？ 此处会再次从不同的角度来讨论P与NP的定义。 “P=NP?” 通常被认为是计算机科学最重要的问题。在很早的时候，就有个数学家毫不客气的指出，P=NP? 是个愚蠢的问题，并且为了嘲笑它，专门在4月1号写了一篇“论文”，称自己证明了 P=NP。 首先，我们要搞清楚什么是“P=NP?” 为此，我们必须先了解一下什么是“算法复杂度”。为此，我们又必须先了解什么是“算法”。我们可以简单的把“算法”想象成一台机器，就跟绞肉机似的。我们给它一些“输入”，它就给我们一些“输出”。比如，绞肉机的输入是肉末，输出是肉渣。牛的输入是草，输出是奶。“加法器”的输入是两个整数，输出是这两个整数的和。“算法理论”所讨论的问题，就是如何设计这些机器，让它们更加有效的工作。就像是说如何培育出优质的奶牛，吃进相同数量的草，更快的产出更多的奶。 世界上的计算问题，都需要“算法”经过一定时间的工作（也叫“计算”），才能得到结果。计算所需要的时间，往往跟“输入”的大小有关系。你的牛吃越是多的草，它就需要越是长时间才能把它们都变成奶。这种草和奶的转换速度，通常被叫做“算法复杂度”。算法复杂度通常被表示为一个函数f(n)，其中n是输入的大小。比如，如果我们的算法复杂度为n^2，那么当输入10个东西的时候，它需要100个单元的时间才能完成计算。当输入100 个东西的时候，它需要10000个单元的时间才能完成。当输入1000个数据的时候，它需要1000000个单元的时间。所谓的“P时间”，多项式时间，就是说这个复杂度函数f(n)是一个多项式。“P=NP?”中的“P”，就是指所有这些复杂度为多项式的算法的“集合”，也就是“所有”的复杂度为多项式的算法。为了简要的描述以下的内容，我定义一些术语： “f(n)时间算法”=“能够在f(n)时间之内，解决某个问题的算法” 当f(n)是个多项式（比如$n^2$）的时候，这就是“多项式时间算法”（P时间算法）。当f(n)是个指数函数（比如$2^n$）的时候，这就是“指数时间算法”（EXPTIME算法）。很多人认为NP问题就是需要指数时间的问题，而NP跟EXPTIME，其实是风马牛不相及的。很显然，P不等于EXPTIME，但是P是否等于NP，却没有一个结论。 现在我来解释一下什么是NP。通常的计算机，都是确定性（deterministic）的。它们在同一个时刻，只有一种行为。如果用程序来表示，那么它们遇到一个条件判断（分支）的时候，只能一次探索其中一条路径。比如： 123456if (x == 0) &#123; one();&#125;else &#123; two();&#125; 在这里，根据x的值是否为零，one()和two()这两个操作，只有一个会发生。然而，有人幻想出来一种机器，叫做“非确定性计算机”（nondeterministic computer），它可以同时运行这程序的两个分支，one()和two()。这有什么用处呢？它的用处就在于，当你不知道x的大小的时候，根据one()和two()是否“运行成功”，你可以推断出x是否为零。这种方式可以同时探索多种可能性。这不是普通的“并行计算”，因为每当遇到一个分支点，非确定性计算机就会产生新的计算单元，用以同时探索这些路径。这机器就像有“分身术”一样。当这种分支点存在于循环（或者递归）里面的时候，它就会反复的产生新的计算单元，新的计算单元又产生更多的计算单元，就跟细胞分裂一样。一般的计算机都没有 这种“超能力”，它们只有固定数目的计算单元。所以他只能先探索一条路径，失败之后，再回过头来探索另外一条。所以，它们似乎要多花一些时间才能得到结果。到这里，基本的概念都有了定义，于是我们可以圆满的给出P和NP的定义。P和NP是这样两个“问题的集合”： P = “确定性计算机”能够在“多项式时间”解决的所有问题NP = “非确定性计算机”能够在“多项式时间”解决的所有问题（注意它们的区别，仅在于“确定性”或者是“非确定性”。） “P=NP?”问题的目标，就是想要知道P和NP这两个集合是否相等。为了证明两个集合（A和 B）相等，一般都要证明两个方向： A 包含 B； B 包含 A。 上一个标题中我们已经说过NP包含了P。因为任何一个非确定性机器，都能被当成一个确定性的机器来用。你只要不使用它的“超能力”，在每个分支点只探索一条路径就行。所以“P=NP?”问题的关键，就在于P是否也包含了NP。也就是说，如果只使用确定性计算机，能否在多项式时间之内，解决所有非确定性计算机能在多项式时间内解决的问题。 我们来细看一下什么是多项式时间（Polynomial time）。我们都知道，$n^2$是多项式，$n^{1000000}$ 也是多项式。多项式与多项式之间，却有天壤之别。把解决问题所需要的时间，用“多项式”这么笼统的概念来描述，其实是非常不准确的做法。在实际的大规模应用中，$n^2$的算法都嫌慢。能找到“多项式时间”的算法，根本不能说明任何问题。对此，理论家们喜欢说，就算再大的多项式(比如 $n^{1000000}$)，也不能和再小的指数函数（比如 $1.0001^n$）相比。因为总是“存在”一个M，当n&gt;M的时候，$1.0001^n$会超过$n^{1000000}$。可是问题的关键，却不在于M的“存在”，而在于它的“大小”。如果你的输入必须达到天文数字才能让指数函数超过多项式的话，那么还不如就用指数复杂度的算法。所以，“P=NP?”这问题的错误就在于，它并没有针对我们的实际需要，而是首先假设了我们有“无穷大”的输入，有“无穷多”的时间和耐心，可以让多项式时间的算法“最终”得到优势。 Reference:[1] 对于“NP难问题”的理解：http://blog.csdn.net/u010021014/article/details/77839858[2] 谈“P=NP?”：http://yinwang0.lofter.com/post/183ec2_4f6312]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>NP-hard</tag>
      </tags>
  </entry>
</search>
